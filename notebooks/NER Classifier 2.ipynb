{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tag import untag, RegexpTagger, BrillTaggerTrainer\n",
    "from nltk.corpus import  conll2002\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import ast "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOC NE Identifier-classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article_id</th>\n",
       "      <th>tagged_title</th>\n",
       "      <th>tagged_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[u'Citan', 'NC', u'none'], [u'a', u'SP', u'no...</td>\n",
       "      <td>[[[u'SAN', u'AQ', u'B-Loc'], [u'PEDRO', 'NC', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  article_id                                       tagged_title  \\\n",
       "0           0           3  [[u'Citan', 'NC', u'none'], [u'a', u'SP', u'no...   \n",
       "\n",
       "                                      tagged_content  \n",
       "0  [[[u'SAN', u'AQ', u'B-Loc'], [u'PEDRO', 'NC', ...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "articles_df = pd.read_csv(\"../files/pos_articles.csv\")\n",
    "print articles_df.shape\n",
    "articles_df.head(1)\n",
    "# articles_df.article_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sentences to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_df(content_vals):\n",
    "    print \"- convert_df\"\n",
    "    s_id = []\n",
    "    s_word = []\n",
    "    s_tag = []\n",
    "    s_iob =[]\n",
    "    s_pos = []\n",
    "    \n",
    "    art_id = []\n",
    "    corpus_sent_id = []\n",
    "    \n",
    "    entity_count = []\n",
    "    token_count = []\n",
    "    csent_id = -1\n",
    "    artid = -1\n",
    "    for sentences in content_vals:\n",
    "        artid += 1\n",
    "        for sent_num in range(len(sentences)):\n",
    "            csent_id += 1\n",
    "            sent = sentences[sent_num]\n",
    "            entity_count.append(0)\n",
    "            token_count.append(0)\n",
    "            for pos in range(len(sent)):\n",
    "                word = sent[pos]\n",
    "                s_id.append(sent_num)\n",
    "                s_word.append(word[0])\n",
    "                s_tag.append(word[1])\n",
    "                s_iob.append(word[2])\n",
    "                s_pos.append(pos)\n",
    "                \n",
    "                art_id.append(artid)\n",
    "                corpus_sent_id.append(csent_id)\n",
    "                if word[2] == \"B-Loc\":\n",
    "                    entity_count[-1] += 1\n",
    "                    token_count[-1]  += 1\n",
    "                elif word[2] == \"I-Loc\":\n",
    "                    token_count[-1] += 1\n",
    "                \n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "            \"sentence\": s_id,\n",
    "            \"word\": s_word,\n",
    "            \"tag\": s_tag,\n",
    "            \"iob\": s_iob,\n",
    "            \"pos\": s_pos,\n",
    "            \"cs_id\": corpus_sent_id,\n",
    "            \"art_id\" : art_id\n",
    "        })\n",
    "    \n",
    "    return df, entity_count, token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ident_features(base_df):\n",
    "    print \"- get features\"\n",
    "    df = pd.DataFrame()\n",
    "    # iob\n",
    "    #clean the iob\n",
    "    base_df.loc[:,\"iob\"] = base_df.iob.apply(lambda x: x if x!=\"B-Org\" else \"none\" )\n",
    "    \n",
    "    le_iob = LabelEncoder()\n",
    "    df.loc[:,\"iob\"] = le_iob.fit_transform(base_df.iob)\n",
    "\n",
    "    #tag\n",
    "    le_tag = LabelEncoder()\n",
    "    df.loc[:,\"tag\"] = le_tag.fit_transform(base_df.tag)\n",
    "\n",
    "    # Uppercase\n",
    "    df.loc[:,\"upper\"] = base_df.word.apply(lambda x: x[0].isupper())\n",
    "    \n",
    "    # Pos\n",
    "    df.loc[:,\"pos\"] = base_df.pos\n",
    "    \n",
    "    #first \n",
    "    df.loc[:,\"first\"] = base_df.pos.apply(lambda x: int(x == 0) )\n",
    "    #size\n",
    "    df.loc[:,\"size\"] = base_df.word.apply(lambda x: len(x))\n",
    "    \n",
    "    #word\n",
    "    df.loc[:,\"word\"] = base_df.word.values\n",
    "    \n",
    "    #sentence\n",
    "    df.loc[:,\"first_sent\"] = base_df.sentence.apply(lambda x: int(x==0)).values\n",
    "#     df.loc[:,\"sent_id\"] = base_df.sentence.values\n",
    "\n",
    "\n",
    "    #corpus_sent_id  this is not a feature but it will be used as reference\n",
    "    df.loc[:,\"cs_id\"] = base_df.cs_id.values\n",
    "    df.loc[:,\"art_id\"] = base_df.art_id.values\n",
    "    \n",
    "    \n",
    "    return df, le_iob, le_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_simple_features(df):\n",
    "    \n",
    "    # add tag features by shifting the list by one or two\n",
    "    tags = df.tag.values.tolist()\n",
    "    df.loc[:,\"prev_1\"] = tags[-1:] + tags[:-1]\n",
    "#     df.at[df[\"pos\"] < 1,'prev_1'] = -1\n",
    "    df.loc[:,\"prev_2\"] = tags[-2:] + tags[:-2]\n",
    "    df.at[df[\"pos\"] < 2,'prev_2'] = -1\n",
    "    \n",
    "#     df.loc[:,\"prev_3\"] = tags[-3:] + tags[:-3]\n",
    "#     df.at[df[\"pos\"] < 3,'prev_3'] = -1\n",
    "    \n",
    "#     df.loc[:,\"prev_4\"] = tags[-4:] + tags[:-4]\n",
    "#     df.at[df[\"pos\"] < 4,'prev_4'] = -1\n",
    "    \n",
    "#     df.loc[:,\"prev_5\"] = tags[-5:] + tags[:-5]\n",
    "#     df.at[df[\"pos\"] < 5,'prev_5'] = -1\n",
    "    \n",
    "    df.loc[:,\"next_1\"] = tags[1:] + tags[:1]\n",
    "    df.loc[:,\"next_2\"] = tags[2:] + tags[:2]\n",
    "#     df.loc[:,\"next_3\"] = tags[3:] + tags[:3]\n",
    "#     df.loc[:,\"next_4\"] = tags[4:] + tags[:4]\n",
    "#     df.loc[:,\"next_5\"] = tags[5:] + tags[:5]\n",
    "    \n",
    "    prefixes = [\"colonia\", \"barrio\", \"residencial\",\"ciudad\", \"aldea\",\"zona\",\"puente\",\"mercado\"]\n",
    "    words = df.word.apply(lambda x: x.lower() ).values.tolist()\n",
    "    df.loc[:,\"prev_prefix_1\"] = words[-1:] + words[:-1]\n",
    "    df.loc[:,\"prev_prefix_1\"]  = df.prev_prefix_1.apply(lambda x:  int( x in prefixes ))\n",
    "    \n",
    "    df.loc[:,\"prev_prefix_2\"] = words[-2:] + words[:-2]\n",
    "    df.loc[:,\"prev_prefix_2\"]  = df.prev_prefix_2.apply(lambda x:  int( x in prefixes ))\n",
    "    \n",
    "    \n",
    "#     iobs = df.iob.values.tolist()\n",
    "#     df.loc[:,\"prevIOB_1\"] = iobs[-1:] + iobs[:-1]\n",
    "#     df.loc[:,\"prevIOB_2\"] = iobs[-2:] + iobs[:-2]\n",
    "    #Next IOB would be cheating\n",
    "#     df.loc[:,\"nextIOB_1\"] = iobs[1:] + iobs[:1]\n",
    "#     df.loc[:,\"nextIOB_2\"] = iobs[2:] + iobs[:2]\n",
    "\n",
    "#     tag_df = pd.get_dummies(df.tag,prefix=\"tag_\")\n",
    "#     for column in tag_df.columns:\n",
    "#         df.loc[:,column] = tag_df[column]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- convert_df\n",
      "- get features\n",
      "(64991, 16)\n",
      "[u'B-Loc' u'I-Loc' u'none']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iob</th>\n",
       "      <th>tag</th>\n",
       "      <th>upper</th>\n",
       "      <th>pos</th>\n",
       "      <th>first</th>\n",
       "      <th>size</th>\n",
       "      <th>word</th>\n",
       "      <th>first_sent</th>\n",
       "      <th>cs_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>prev_1</th>\n",
       "      <th>prev_2</th>\n",
       "      <th>next_1</th>\n",
       "      <th>next_2</th>\n",
       "      <th>prev_prefix_1</th>\n",
       "      <th>prev_prefix_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SAN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>PEDRO</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>SULA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Hasta</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iob  tag  upper  pos  first  size   word  first_sent  cs_id  art_id  \\\n",
       "0    0    1   True    0      1     3    SAN           1      0       0   \n",
       "1    1   21   True    1      0     5  PEDRO           1      0       0   \n",
       "2    1   21   True    2      0     4   SULA           1      0       0   \n",
       "3    2   12  False    0      1     1      -           0      1       0   \n",
       "4    2   33   True    1      0     5  Hasta           0      1       0   \n",
       "\n",
       "   prev_1  prev_2  next_1  next_2  prev_prefix_1  prev_prefix_2  \n",
       "0      27      -1      21      21              0              0  \n",
       "1       1      -1      21      12              0              0  \n",
       "2      21       1      12      33              0              0  \n",
       "3      21      -1      33       4              0              0  \n",
       "4      12      -1       4      21              0              0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting strings to objects \n",
    "# articles_df.tagged_content =articles_df.tagged_content.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "content_vals = articles_df.tagged_content.values\n",
    "\n",
    "\n",
    "words_df, entity_count, token_count = convert_df(content_vals)\n",
    "features_df, le_iob, le_tag = get_ident_features(words_df)\n",
    "features_df = extract_simple_features(features_df)\n",
    "\n",
    "print features_df.shape\n",
    "print le_iob.classes_\n",
    "features_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average entity per sentence\n",
      "0.448767833982\n",
      "average tokens per sentence\n",
      "0.772589710333\n",
      "avg entities per sentence in train set\n",
      "0.45027027027\n",
      "number of sentences in train set: 1850\n",
      "avg entities per sentence in test set\n",
      "0.442764578834\n",
      "number of sentences in train set: 463\n"
     ]
    }
   ],
   "source": [
    "print \"average entity per sentence\"\n",
    "print sum(entity_count) * 1.0 / len(entity_count)\n",
    "print \"average tokens per sentence\"\n",
    "print sum(token_count) * 1.0 / len(token_count)\n",
    "\n",
    "#split using sentence entity count\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True, random_state= 233 )\n",
    "for train_index, test_index in skf.split([0 for i in range(len(entity_count))], entity_count):\n",
    "    X_train = features_df[features_df[\"cs_id\"].isin( train_index )].drop([\"word\",\"iob\", \"cs_id\",\"art_id\"],1).values\n",
    "    X_test = features_df[features_df[\"cs_id\"].isin( test_index )].drop([\"word\",\"iob\", \"cs_id\",\"art_id\"],1).values\n",
    "\n",
    "    y_train = features_df[features_df[\"cs_id\"].isin( train_index )].iob.values\n",
    "    y_test = features_df[features_df[\"cs_id\"].isin( test_index )].iob.values\n",
    "    \n",
    "    entity_count_train = [entity_count[i] for i in train_index]\n",
    "    entity_count_test = [entity_count[i] for i in test_index]\n",
    "    \n",
    "    break\n",
    "\n",
    "    \n",
    "print \"avg entities per sentence in train set\"  \n",
    "print sum(entity_count_train) * 1.0 / len(entity_count_train)\n",
    "print \"number of sentences in train set: %i\"  %len(train_index)\n",
    "print \"avg entities per sentence in test set\"  \n",
    "print sum(entity_count_test) * 1.0 / len(entity_count_test)\n",
    "print \"number of sentences in train set: %i\"  %len(test_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = features_df.drop([\"word\",\"iob\"],1).values\n",
    "# y = features_df.iob.values\n",
    "\n",
    "# # split to X_train and X_test\n",
    "# skf = StratifiedKFold(n_splits=10,shuffle=True, random_state= 233 )\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train classifier\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607688319613\n",
      "{'min_samples_split': 4, 'n_estimators': 200, 'max_depth': 20}\n",
      "[ 0.91227813]\n",
      "[ 0.60768832]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "f_one_scorer = make_scorer(f1_score,average=\"weighted\", labels=[0,1] )\n",
    "\n",
    "print \"- train classifier\"\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [200],\n",
    "#     \"max_depth\": [ 3,4,10,16,20],\n",
    "#     \"min_samples_split\" : [4,10,20]\n",
    "# }\n",
    "parameters = {\n",
    "    \"n_estimators\": [200],\n",
    "    \"max_depth\": [20],\n",
    "    \"min_samples_split\" : [4]\n",
    "}\n",
    "clf = RandomForestClassifier(random_state= 233, n_jobs=4)\n",
    "clf = GridSearchCV(clf, parameters, cv=5, scoring= f_one_scorer, verbose=1 )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print clf.best_score_\n",
    "\n",
    "print clf.best_params_\n",
    "\n",
    "print clf.cv_results_['mean_train_score']\n",
    "print clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train Results -\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.93       833\n",
      "          1       0.97      0.78      0.87       596\n",
      "\n",
      "avg / total       0.97      0.85      0.90      1429\n",
      "\n",
      "- Test Results -\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.71      0.78       205\n",
      "          1       0.85      0.48      0.61       153\n",
      "\n",
      "avg / total       0.86      0.61      0.71       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"- Train Results -\"\n",
    "preds_train = clf.predict(X_train)\n",
    "print(classification_report(y_train, preds_train,labels=[0,1]))\n",
    "print \"- Test Results -\"\n",
    "preds_test = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds_test,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0       0.82      0.65      0.73       104\n",
    "1       0.93      0.51      0.66        75\n",
    "\n",
    "\n",
    "0       0.82      0.64      0.72       104\n",
    "1       0.90      0.48      0.63        75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51917, 12)\n",
      "13\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "preds_train_rf = clf.predict(X_train)\n",
    "preds_test_rf = clf.predict(X_test)\n",
    "\n",
    "X_train2 = np.column_stack( (X_train, preds_train_rf) )\n",
    "X_test2 = np.column_stack( (X_test, preds_test_rf) )\n",
    "print len(X_train2[0])  #just to know whats the last one\n",
    "print X_train2[:10,12]\n",
    "print preds_train_rf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51917, 17)\n",
      "(13074, 17)\n"
     ]
    }
   ],
   "source": [
    "#weird uggly algorithm to get the prevNE stacked tag\n",
    "def getStackedFeatures(X):\n",
    "    prevNE = []\n",
    "    nextNE = []\n",
    "    for index, row in enumerate(X):\n",
    "        if index == 0:\n",
    "            prevNE.append( 2 )\n",
    "        else:\n",
    "            prevNE.append( X[index-1,-1] )\n",
    "\n",
    "        if index == len(X)-1:\n",
    "            nextNE.append( 2 )\n",
    "        else:\n",
    "            nextNE.append( X[index+1,-1] )\n",
    "\n",
    "    X2 = np.column_stack( (X, prevNE) )\n",
    "    X2 = np.column_stack( (X2, nextNE) )\n",
    "\n",
    "    # #pos -2 and pos +2\n",
    "    X2 = np.column_stack( (X2, prevNE[-2:] + prevNE[:-2]) )\n",
    "    X2 = np.column_stack( (X2, nextNE[2:]  + nextNE[:2]) )\n",
    "\n",
    "    print X2.shape\n",
    "    return X2\n",
    "\n",
    "X_train2 = getStackedFeatures(X_train2)\n",
    "X_test2 = getStackedFeatures(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split to X_train and X_test\n",
    "# skf = StratifiedKFold(n_splits=10,shuffle=True, random_state= 233 )\n",
    "# for train_index, test_index in skf.split(X3, y):\n",
    "# X2_train, X2_test = X3[train_index], X3[test_index]\n",
    "# y2_train, y2_test = y[train_index], y[test_index]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train classifier\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933270555232\n",
      "{'min_samples_split': 4, 'n_estimators': 200, 'max_depth': 20}\n",
      "[ 0.96009759]\n",
      "[ 0.93327056]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "f_one_scorer = make_scorer(f1_score,average=\"weighted\", labels=[0,1] )\n",
    "\n",
    "print \"- train classifier\"\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [200],\n",
    "#     \"max_depth\": [ 3,4,10,16,20],\n",
    "#     \"min_samples_split\" : [4,10,20]\n",
    "# }\n",
    "parameters = {\n",
    "    \"n_estimators\": [200],\n",
    "    \"max_depth\": [20],\n",
    "    \"min_samples_split\" : [4]\n",
    "}\n",
    "clf2 = RandomForestClassifier(random_state= 233, n_jobs=4)\n",
    "clf2 = GridSearchCV(clf2, parameters, cv=5, scoring= f_one_scorer, verbose=1 )\n",
    "\n",
    "clf2.fit(X_train2, y_train)\n",
    "\n",
    "print clf2.best_score_\n",
    "\n",
    "print clf2.best_params_\n",
    "\n",
    "print clf2.cv_results_['mean_train_score']\n",
    "print clf2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Train Results -\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96       833\n",
      "          1       0.99      0.93      0.96       596\n",
      "\n",
      "avg / total       0.98      0.94      0.96      1429\n",
      "\n",
      "- Test Results -\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.73      0.79       205\n",
      "          1       0.86      0.64      0.73       153\n",
      "\n",
      "avg / total       0.87      0.69      0.77       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"- Train Results -\"\n",
    "preds_train2 = clf2.predict(X_train2)\n",
    "print(classification_report(y_train, preds_train2,labels=[0,1]))\n",
    "print \"- Test Results -\"\n",
    "preds_test2 = clf2.predict(X_test2)\n",
    "print(classification_report(y_test, preds_test2,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0       0.82      0.64      0.72       104\n",
    "1       0.90      0.48      0.63        75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure whole Named Entities recognition... somehow\n",
    "\n",
    "Up until now we've just done token-based evaluation... now the idea is to make entity-based evaluation.\n",
    "**Entity-Based evaluation** will be defined like this:\n",
    "\n",
    "The algorithm must match exactly the full entity if it misses a token it should be considered an error.\n",
    "\n",
    "So suppose that the true values are:\n",
    "\n",
    "[ \"San Marcos\", \"Los Dolores\", **\"El Carrizal\"**, **\"Navarro\"** ]\n",
    "\n",
    "and that the model identified:\n",
    "\n",
    "[ **\"Miguel\"**, \"San Marcos\", \"Los Dolores\", **\"Carrizal\"**]  \n",
    "\n",
    "\n",
    "then \n",
    "\n",
    "\n",
    "**precision** =   len([\"San Marcos\",\"Los Dolores\" ]) / ( len([\"San Marcos\",\"Los Dolores\" ]) + len([\"Miguel\", \"Carrizal\"]) )\n",
    "\n",
    "and \n",
    "\n",
    "**recall**  = len([\"San Marcos\",\"Los Dolores\" ]) / ( len([\"San Marcos\",\"Los Dolores\" ]) + len([\"El Carrizal\", \"Navarro\"]) )\n",
    "\n",
    "### Strategy\n",
    "\n",
    "1) get all true values with artid, sentid, posid, entity  format\n",
    "\n",
    "2) predict values and store them in artid, sentid, posid, entity  format\n",
    "\n",
    "3) compare true values against predicted get recall\n",
    "\n",
    "4) compare predicted against true values get precision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 get all true values with artid, sentid, posid, entity format\n",
    "\n",
    "def get_true_values(df):\n",
    "    art_id = []\n",
    "    s_id = []\n",
    "    s_word = []\n",
    "    s_tag = []\n",
    "    s_iob =[]\n",
    "    s_pos = []\n",
    "    \n",
    "    corpus_sent_id = []\n",
    "    csent_id = -1\n",
    "    artid = -1\n",
    "    for index, article in df.iterrows():\n",
    "        sentences = article[\"tagged_content\"]\n",
    "        artid += 1\n",
    "        for sent_num in range(len(sentences)):\n",
    "            sent = sentences[sent_num]\n",
    "            csent_id += 1\n",
    "            for pos in range(len(sent)):\n",
    "                word = sent[pos]\n",
    "                \n",
    "                if word[2][0] == \"B\":\n",
    "                    corpus_sent_id.append(csent_id)\n",
    "                    art_id.append(artid)\n",
    "                    s_id.append(sent_num)\n",
    "                    s_pos.append(pos)\n",
    "                    s_word.append(word[0])\n",
    "                    s_iob.append(word[2])\n",
    "                elif word[2][0] == \"I\":\n",
    "                    \n",
    "\n",
    "                    s_word[-1] += \" \" + word[0]\n",
    "                    \n",
    "                \n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "            \"art_id\": art_id,\n",
    "#             \"sent_id\": s_id,\n",
    "            \"pos\": s_pos,\n",
    "            \"word\": s_word,\n",
    "            \"cs_id\": corpus_sent_id\n",
    "        })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "true_values = get_true_values(articles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>cs_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SAN PEDRO SULA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>San Pedro Sula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Lomas del Carmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>Monumento a la Madre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>primera avenida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>parque central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>San Pedro Sula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>TEGUCIGALPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>TEGUCIGALPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_id  cs_id  pos                  word\n",
       "0       0      0    0        SAN PEDRO SULA\n",
       "1       0      2   13        San Pedro Sula\n",
       "2       0      3   38      Lomas del Carmen\n",
       "3       0      5   19  Monumento a la Madre\n",
       "4       0      5   24       primera avenida\n",
       "5       0      5   27        parque central\n",
       "6       0      7   11        San Pedro Sula\n",
       "7       1     10    0           TEGUCIGALPA\n",
       "8       2     21    0           TEGUCIGALPA\n",
       "9       2     29    9               Kennedy"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values.head(10)\n",
    "# articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_train = features_df[features_df[\"cs_id\"].isin( train_index )][[\"art_id\",\"cs_id\",\"pos\", \"word\"]].values\n",
    "words_test = features_df[features_df[\"cs_id\"].isin( test_index )][[\"art_id\",\"cs_id\",\"pos\", \"word\"]].values\n",
    "\n",
    "\n",
    "preds_train2[:10]\n",
    "\n",
    "# corpus_sent_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIdentifiedEntities(words, preds):\n",
    "    entities = []\n",
    "    last_index = -1\n",
    "    for index, pred in enumerate(preds):\n",
    "        \n",
    "        if pred == 0:  #B-Loc\n",
    "            entities.append(words[index])\n",
    "            last_index = index\n",
    "        elif pred == 1 and last_index == index-1 : #I-Loc\n",
    "            entities[-1][3] += \" \" + words[index][3]\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(entities,columns=[\"art_id\",\"cs_id\", \"pos\", \"word\"] )\n",
    "            \n",
    "    return df\n",
    "            \n",
    "train_identified = getIdentifiedEntities (words_train,preds_train2 ) \n",
    "test_identified = getIdentifiedEntities (words_test,preds_test2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_true = true_values[true_values[\"cs_id\"].isin( train_index )].sort_values(by=[\"art_id\"])\n",
    "test_true = true_values[true_values[\"cs_id\"].isin( test_index )].sort_values(by=[\"art_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train ---\n",
      "true positives: 632\n",
      "predicted: 797\n",
      "precision: 0.7930\n",
      "--- test ---\n",
      "true positives: 119\n",
      "predicted: 171\n",
      "precision: 0.6959\n"
     ]
    }
   ],
   "source": [
    "def getPrecision(pred, true):\n",
    "    true_positive = 0\n",
    "    for index, entity in pred.iterrows():\n",
    "        result = true[(true[\"cs_id\"] == entity.cs_id)\n",
    "                      & (true[\"pos\"] == entity.pos)\n",
    "                      & (true[\"word\"] == entity.word)\n",
    "                     ]\n",
    "        if len(result) > 0:\n",
    "            true_positive += 1\n",
    "    \n",
    "    print \"true positives: %i\" %true_positive\n",
    "    print \"predicted: %i\" % pred.shape[0]\n",
    "    precision = true_positive * 1.0 / pred.shape[0]\n",
    "    print \"precision: %0.4f\" %precision\n",
    "    \n",
    "print \"--- train ---\"\n",
    "getPrecision(train_identified, train_true)   \n",
    "print \"--- test ---\"\n",
    "getPrecision(test_identified, test_true)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train ---\n",
      "true positives: 632\n",
      "positives: 834\n",
      "recall: 0.7578\n",
      "--- test ---\n",
      "true positives: 119\n",
      "positives: 206\n",
      "recall: 0.5777\n"
     ]
    }
   ],
   "source": [
    "def getRecall(pred, true):\n",
    "    true_positive = 0\n",
    "    for index, entity in true.iterrows():\n",
    "        result = pred[(pred[\"cs_id\"] == entity.cs_id)\n",
    "                      & (pred[\"pos\"] == entity.pos)\n",
    "                      & (pred[\"word\"] == entity.word)\n",
    "                     ]\n",
    "        if len(result) > 0:\n",
    "            true_positive += 1\n",
    "    \n",
    "    print \"true positives: %i\" %true_positive\n",
    "    print \"positives: %i\" % true.shape[0]\n",
    "    recall = true_positive * 1.0 / true.shape[0]\n",
    "    print \"recall: %0.4f\" %recall\n",
    "    \n",
    "print \"--- train ---\"  \n",
    "getRecall(train_identified, train_true)\n",
    "print \"--- test ---\"\n",
    "getRecall(test_identified, test_true)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
