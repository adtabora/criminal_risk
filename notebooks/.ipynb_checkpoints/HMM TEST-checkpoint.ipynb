{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report, precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import unicodedata\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>relationships</th>\n",
       "      <th>tagged_title</th>\n",
       "      <th>tagged_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[[{u'tag': u'B-Col', u'word': u'lomas del carm...</td>\n",
       "      <td>[[u'Citan', 'NC', u'none'], [u'a', u'SP', u'no...</td>\n",
       "      <td>[[[SAN, AQ, B-City], [PEDRO, NC, I-City], [SUL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[u'DEI', 'NC', u'none'], [u'pide', u'VMI', u'...</td>\n",
       "      <td>[[[TEGUCIGALPA, NC, B-City]], [[-, Fg, none], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[[{u'tag': u'B-Col', u'word': u'kennedy'}, {u'...</td>\n",
       "      <td>[[u'Alcald\\xeda', 'NC', u'none'], [u'intensifi...</td>\n",
       "      <td>[[[TEGUCIGALPA, NC, B-City]], [[-, Fg, none], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>[[{u'tag': u'B-City', u'word': u'puerto cortes...</td>\n",
       "      <td>[[u'Pasajeros', 'NC', u'none'], [u'asaltantes'...</td>\n",
       "      <td>[[[PUERTO, NC, B-City], [CORTES, NC, I-City], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>[[{u'tag': u'B-City', u'word': u'juticalpa'}, ...</td>\n",
       "      <td>[[u'Fallece', 'NC', u'none'], [u'comerciante',...</td>\n",
       "      <td>[[[JUTICALPA, NC, B-City], [,, Fc, none], [Ola...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                      relationships  \\\n",
       "0           3  [[{u'tag': u'B-Col', u'word': u'lomas del carm...   \n",
       "1           5                                                 []   \n",
       "2           9  [[{u'tag': u'B-Col', u'word': u'kennedy'}, {u'...   \n",
       "3          11  [[{u'tag': u'B-City', u'word': u'puerto cortes...   \n",
       "4          12  [[{u'tag': u'B-City', u'word': u'juticalpa'}, ...   \n",
       "\n",
       "                                        tagged_title  \\\n",
       "0  [[u'Citan', 'NC', u'none'], [u'a', u'SP', u'no...   \n",
       "1  [[u'DEI', 'NC', u'none'], [u'pide', u'VMI', u'...   \n",
       "2  [[u'Alcald\\xeda', 'NC', u'none'], [u'intensifi...   \n",
       "3  [[u'Pasajeros', 'NC', u'none'], [u'asaltantes'...   \n",
       "4  [[u'Fallece', 'NC', u'none'], [u'comerciante',...   \n",
       "\n",
       "                                      tagged_content  \n",
       "0  [[[SAN, AQ, B-City], [PEDRO, NC, I-City], [SUL...  \n",
       "1  [[[TEGUCIGALPA, NC, B-City]], [[-, Fg, none], ...  \n",
       "2  [[[TEGUCIGALPA, NC, B-City]], [[-, Fg, none], ...  \n",
       "3  [[[PUERTO, NC, B-City], [CORTES, NC, I-City], ...  \n",
       "4  [[[JUTICALPA, NC, B-City], [,, Fc, none], [Ola...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df = pd.read_csv(\"../files/pos_articles.csv\")\n",
    "articles_df.tagged_content = articles_df.tagged_content.apply(lambda x: ast.literal_eval(x))\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>cs_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>num_entities</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[SAN, AQ, B-City], [PEDRO, NC, I-City], [SULA...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-, Fg, none], [Hasta, SP, none], [el, DA, no...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[Los, DA, none], [operativos, AQ, none], [con...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[[Resaltó, VMI, none], [que, CS, none], [graci...</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[[Indicó, VMI, none], [que, CS, none], [tienen...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_id  sent_id  cs_id                                           sentence  \\\n",
       "0       3        0      0  [[SAN, AQ, B-City], [PEDRO, NC, I-City], [SULA...   \n",
       "1       3        1      1  [[-, Fg, none], [Hasta, SP, none], [el, DA, no...   \n",
       "2       3        2      2  [[Los, DA, none], [operativos, AQ, none], [con...   \n",
       "3       3        3      3  [[Resaltó, VMI, none], [que, CS, none], [graci...   \n",
       "4       3        4      4  [[Indicó, VMI, none], [que, CS, none], [tienen...   \n",
       "\n",
       "   num_entities  num_words  \n",
       "0             1          3  \n",
       "1             1         32  \n",
       "2             1         16  \n",
       "3             1         42  \n",
       "4             0         35  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def articlesToSentences(df):\n",
    "    #convert to sentences\n",
    "    sentences = []\n",
    "    cs_id = -1 #corpus sentence id\n",
    "    for artid, article in df.iterrows():\n",
    "        for sentid, sentence in enumerate(article.tagged_content):\n",
    "            cs_id += 1\n",
    "            num_entities = 0\n",
    "            for word in sentence:\n",
    "                if word[2][0] == \"B\":\n",
    "                    num_entities += 1 \n",
    "            sentences.append([article.article_id,sentid,cs_id,sentence, num_entities,len(sentence)])\n",
    "    \n",
    "    return pd.DataFrame(sentences,columns=[\"art_id\",\"sent_id\",\"cs_id\",\"sentence\",\"num_entities\",\"num_words\"])\n",
    "        \n",
    "sentences_df = articlesToSentences(articles_df)    \n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True, random_state= 773 )  #233\n",
    "for train_index, test_index in skf.split( sentences_df, sentences_df.num_entities.tolist()):\n",
    "    sentences_train = sentences_df.loc[train_index]\n",
    "    sentences_test = sentences_df.loc[test_index]\n",
    "    break #we only need one iteration since it is a simple split\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert To Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>cs_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>iob_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>Fg</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hasta</td>\n",
       "      <td>SP</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>el</td>\n",
       "      <td>DA</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>momento</td>\n",
       "      <td>NC</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ocho</td>\n",
       "      <td>DN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_id  sent_id  cs_id  pos     word pos_tag iob_tag\n",
       "0       3        1      1    0        -      Fg    none\n",
       "1       3        1      1    1    Hasta      SP    none\n",
       "2       3        1      1    2       el      DA    none\n",
       "3       3        1      1    3  momento      NC    none\n",
       "4       3        1      1    4     ocho      DN    none"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertToWords(sentences):\n",
    "    data =[]\n",
    "    for _, sent in sentences.iterrows():\n",
    "        for pos, word in enumerate(sent.sentence):\n",
    "            data.append([sent.art_id, sent.sent_id, sent.cs_id, pos, word[0],word[1],word[2]])\n",
    "    return pd.DataFrame(data,columns=[\"art_id\",\"sent_id\",\"cs_id\",\"pos\",\"word\",\"pos_tag\",\"iob_tag\"])\n",
    "words_train = convertToWords(sentences_train)\n",
    "words_test = convertToWords(sentences_test)\n",
    "words_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>cs_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>iob_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SAN</td>\n",
       "      <td>AQ</td>\n",
       "      <td>B-City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PEDRO</td>\n",
       "      <td>NC</td>\n",
       "      <td>I-City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SULA</td>\n",
       "      <td>NC</td>\n",
       "      <td>I-City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>La</td>\n",
       "      <td>DA</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Policía</td>\n",
       "      <td>NC</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_id  sent_id  cs_id  pos     word pos_tag iob_tag\n",
       "0       3        0      0    0      SAN      AQ  B-City\n",
       "1       3        0      0    1    PEDRO      NC  I-City\n",
       "2       3        0      0    2     SULA      NC  I-City\n",
       "3       3        6      6    0       La      DA    none\n",
       "4       3        6      6    1  Policía      NC    none"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# very useful function to avoid mispellings problems.\n",
    "def to_ascii(s):\n",
    "    return unicodedata.normalize('NFKD', s).encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds if a word or a group of words are contained in a gazette\n",
    "# words parameter is a list of 5 words where the 3rd word is the base word \n",
    "# and the others are the previous or next words\n",
    "def entity_in_gazette(words,gazette):\n",
    "    #use base word\n",
    "    if words[2] in gazette:\n",
    "        return 1\n",
    "    # bigram\n",
    "    elif \" \".join(words[1:3]) in gazette \\\n",
    "        or \" \".join(words[2:4]) in gazette:\n",
    "        return 1\n",
    "    # trigram\n",
    "    elif  \" \".join(words[0:3]) in gazette \\\n",
    "        or \" \".join(words[1:4]) in gazette \\\n",
    "        or \" \".join(words[2:5]) in gazette:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatures(df, le_iob=None, le_tag=None):\n",
    "    print \"- getting features\"\n",
    "    # iob\n",
    "    if le_iob == None:\n",
    "        le_iob = LabelEncoder()\n",
    "        le_iob.fit(df.iob_tag)\n",
    "    df.loc[:,\"iob_tag\"] = le_iob.transform(df.iob_tag)\n",
    "\n",
    "    print \"-- iob tag classes\"\n",
    "    print le_iob.classes_\n",
    "    # tag\n",
    "    if le_tag == None:\n",
    "        le_tag = LabelEncoder()\n",
    "        le_tag.fit(df.pos_tag)\n",
    "    df.loc[:,\"pos_tag\"] = le_tag.transform(df.pos_tag)\n",
    "    # print \"-- pos tag classes\"\n",
    "    # print le_tag.classes_\n",
    "    # If word first letter is uppercase\n",
    "    df.loc[:,\"upper\"] = df.word.apply(lambda x: int(x[0].isupper()) )\n",
    "    upper = df.upper.values.tolist()\n",
    "    df.loc[:,\"upper_prev1\"] = [0] + upper[:-1]\n",
    "    df.loc[:,\"upper_next1\"] =  upper[1:] + [0]\n",
    "    # first word in sentence\n",
    "    df.loc[:,\"first\"] = df.pos.apply(lambda x: int(x == 0) )\n",
    "    # size\n",
    "    df.loc[:,\"size\"] = df.word.apply(lambda x: len(x))\n",
    "    # first sentence\n",
    "    df.loc[:,\"first_sent\"] = df.sent_id.apply(lambda x: int(x==0)).values\n",
    "\n",
    "    # TAGS\n",
    "    # add tag features by shifting the tag list \n",
    "    tags = df.pos_tag.values.tolist()\n",
    "\n",
    "    df.loc[:,\"prev_1\"] = tags[-1:] + tags[:-1]\n",
    "    # df.at[df[\"pos\"] < 1,'prev_1'] = -1\n",
    "    df.loc[:,\"prev_2\"] = tags[-2:] + tags[:-2]\n",
    "    df.at[df[\"pos\"] < 2,'prev_2'] = -1\n",
    "\n",
    "    df.loc[:,\"next_1\"] = tags[1:] + tags[:1]\n",
    "    df.loc[:,\"next_2\"] = tags[2:] + tags[:2]\n",
    "\n",
    "    # PREVIOUS WORDS (In spanish the type of location are written before the NE )\n",
    "    loc_types = [\"colonia\", \"barrio\", \"residencial\",\"ciudad\", \n",
    "    \"aldea\",\"zona\",\"puente\",\"mercado\",\"bulevar\",\"centro\",\"estado\"]\n",
    "    words = df.word.apply(lambda x: x.lower() ).values.tolist()\n",
    "    df.loc[:,\"prev_prefix_1\"] = words[-1:] + words[:-1]\n",
    "    df.loc[:,\"prev_prefix_1\"]  = df.prev_prefix_1.apply(lambda x:  int( x in loc_types ))\n",
    "    \n",
    "    df.loc[:,\"prev_prefix_2\"] = words[-2:] + words[:-2]\n",
    "    df.loc[:,\"prev_prefix_2\"]  = df.prev_prefix_2.apply(lambda x:  int( x in loc_types ))\n",
    "\n",
    "    #Gazette features\n",
    "    countries_df = pd.read_csv(\"../files/countries.csv\", encoding=\"utf-8\")\n",
    "    dep_mun_df = pd.read_csv(\"../files/DepartamentosMunicipios.csv\", encoding=\"utf-8\")\n",
    "    world_cities = pd.read_csv(\"../files/ciudades_mundo.csv\", encoding=\"utf-8\")\n",
    "    #converting to ascii because of accents (tilde)\n",
    "    countries_df.value = countries_df.value.apply(lambda x: to_ascii(x).lower() )\n",
    "    dep_mun_df.Departamento = dep_mun_df.Departamento.apply(lambda x: to_ascii(x).lower() )\n",
    "    dep_mun_df.Municipio = dep_mun_df.Municipio.apply(lambda x: to_ascii(x).lower() )\n",
    "    world_cities.city = world_cities.city.apply(lambda x: to_ascii(x).lower() )\n",
    "\n",
    "    country = []\n",
    "    state = []\n",
    "    city = []\n",
    "\n",
    "    words = df.word.apply(lambda x: to_ascii(x).lower() ).values.tolist()\n",
    "    prev_2 = [\"\",\"\"] + words[:-2]\n",
    "    prev_1 = [\"\"] + words[:-1]\n",
    "    next_1 = words[1:] + [\"\"]\n",
    "    next_2 = words[2:] + [\"\",\"\"]\n",
    "\n",
    "    #convert to dummies\n",
    "    # columns = [\"prev_1\", \"prev_2\",\"next_1\",\"next_2\",\"pos_tag\"]\n",
    "    # df = hot_encode(df,columns)\n",
    "\n",
    "    \n",
    "    \n",
    "    #Sentence Size\n",
    "    sentence_size = pd.DataFrame({\n",
    "        \"cs_id\":df.cs_id.value_counts().index.values,\n",
    "        \"sent_size\": df.cs_id.value_counts().values\n",
    "    })\n",
    "    \n",
    "    \n",
    "    df = df.merge(sentence_size, left_on='cs_id', right_on='cs_id', how='left')\n",
    "\n",
    "    cities_gazette = np.concatenate([dep_mun_df.Municipio.values, world_cities.city.values])\n",
    "\n",
    "    for idx in range(len(words)):\n",
    "        word_list = [prev_2[idx],prev_1[idx],words[idx],next_1[idx],next_2[idx]]\n",
    "        \n",
    "        country.append( entity_in_gazette(word_list,countries_df.value.values) )\n",
    "        state.append( entity_in_gazette(word_list,dep_mun_df.Departamento.values) )\n",
    "        city.append( entity_in_gazette(word_list, cities_gazette ) )\n",
    "\n",
    "    df.loc[:,\"in_Country\"] = country\n",
    "    df.loc[:,\"in_State\"] = state\n",
    "    df.loc[:,\"in_City\"] = city\n",
    "    \n",
    "    return df, le_iob, le_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- getting features\n",
      "-- iob tag classes\n",
      "[u'B-Bar' u'B-City' u'B-Col' u'B-Country' u'B-Misc' u'B-Res' u'B-State'\n",
      " u'B-Zone' u'I-Bar' u'I-City' u'I-Col' u'I-Country' u'I-Misc' u'I-Res'\n",
      " u'I-State' u'I-Zone' u'none']\n",
      "- getting features\n",
      "-- iob tag classes\n",
      "[u'B-Bar' u'B-City' u'B-Col' u'B-Country' u'B-Misc' u'B-Res' u'B-State'\n",
      " u'B-Zone' u'I-Bar' u'I-City' u'I-Col' u'I-Country' u'I-Misc' u'I-Res'\n",
      " u'I-State' u'I-Zone' u'none']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>cs_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>iob_tag</th>\n",
       "      <th>upper</th>\n",
       "      <th>upper_prev1</th>\n",
       "      <th>upper_next1</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_1</th>\n",
       "      <th>prev_2</th>\n",
       "      <th>next_1</th>\n",
       "      <th>next_2</th>\n",
       "      <th>prev_prefix_1</th>\n",
       "      <th>prev_prefix_2</th>\n",
       "      <th>sent_size</th>\n",
       "      <th>in_Country</th>\n",
       "      <th>in_State</th>\n",
       "      <th>in_City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hasta</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>el</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>momento</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ocho</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   art_id  sent_id  cs_id  pos     word  pos_tag  iob_tag  upper  upper_prev1  \\\n",
       "0       3        1      1    0        -       13       16      0            0   \n",
       "1       3        1      1    1    Hasta       34       16      1            0   \n",
       "2       3        1      1    2       el        4       16      0            1   \n",
       "3       3        1      1    3  momento       22       16      0            0   \n",
       "4       3        1      1    4     ocho        7       16      0            0   \n",
       "\n",
       "   upper_next1   ...     prev_1  prev_2  next_1  next_2  prev_prefix_1  \\\n",
       "0            1   ...         28      -1      34       4              0   \n",
       "1            0   ...         13      -1       4      22              0   \n",
       "2            0   ...         34      13      22       7              0   \n",
       "3            0   ...          4      34       7      22              0   \n",
       "4            0   ...         22       4      22      35              0   \n",
       "\n",
       "   prev_prefix_2  sent_size  in_Country  in_State  in_City  \n",
       "0              0         32           0         0        0  \n",
       "1              0         32           0         0        0  \n",
       "2              0         32           0         0        0  \n",
       "3              0         32           0         0        0  \n",
       "4              0         32           0         0        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_tag = LabelEncoder()\n",
    "le_tag.fit(words_train.pos_tag.values.tolist() + words_test.pos_tag.values.tolist()  )\n",
    "\n",
    "features_train, le_iob, _ = getFeatures(words_train.copy(), le_tag= le_tag)\n",
    "features_test,_,_ = getFeatures(words_test.copy(), le_iob=le_iob, le_tag=le_tag)\n",
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train HMM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# formats in X and y\n",
    "def getXY(df, dropColumns, includeColumns=None, names=False):\n",
    "    df = addNewFeatures(df)\n",
    "    if includeColumns == None:\n",
    "        X = df.drop(dropColumns, 1).values\n",
    "    else:\n",
    "        X = df[includeColumns].values\n",
    "    y = df.iob_tag.values\n",
    "    # print \"-- iob counts --\"\n",
    "    # print df.iob.value_counts()\n",
    "    if names:\n",
    "        features_names = df.drop(dropColumns, 1).columns\n",
    "        return X, y, features_names\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_columns = [\"art_id\",\"sent_id\", \"cs_id\",\"word\", \"iob_tag\" ]\n",
    "X_train, y_train, features_names = getXY(features_train, desc_columns, names=True)\n",
    "X_test, y_test = getXY(features_test, desc_columns)\n",
    "len_train = sentences_train[\"num_words\"].values.tolist()\n",
    "len_test = sentences_test[\"num_words\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55517\n",
      "(55387, 25)\n"
     ]
    }
   ],
   "source": [
    "# ----------------  AQUI   --------------------#\n",
    "# You need to see why these numbers aren't matching before continuing\n",
    "print sum(len_train)\n",
    "print train_df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 55401 is out of bounds for axis 0 with size 55387",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-74ea0c3f4e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseqlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialHMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialHMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"- Train Results -\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alextabora/anaconda/lib/python2.7/site-packages/seqlearn/hmm.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, lengths)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0minit_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0minit_prob\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mfinal_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 55401 is out of bounds for axis 0 with size 55387"
     ]
    }
   ],
   "source": [
    "from seqlearn.hmm import MultinomialHMM\n",
    "clf = MultinomialHMM()\n",
    "clf.fit(X_train, y_train, len_train)\n",
    "print \"- Train Results -\"\n",
    "preds_train = clf.predict(X_train)\n",
    "print classification_report(y_train, preds_train )\n",
    "\n",
    "print \"- Test Results -\"\n",
    "preds_test = clf.predict(X_test)\n",
    "print classification_report(y_test, preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
