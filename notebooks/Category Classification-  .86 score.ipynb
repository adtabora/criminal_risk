{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook is to test the classifier.\n",
    "It will involve a little of data exploration, feature extraction using bag of words and training a classifier. \n",
    "\n",
    "Later the code will be codified into python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_df = pd.read_csv(\"../files/documents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Auditoría revela irregularidades en el Parlacen</td>\n",
       "      <td>GUATEMALA.- Una fiscalización de la Contralorí...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Suspendidas las citas en Hospital Escuela</td>\n",
       "      <td>TEGUCIGALPA.- Una misteriosa obstrucción del s...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mariscos contaminados alarman a los “porteños”</td>\n",
       "      <td>PUERTO CORTES, Cortés.- Alarmados se encuentra...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Citan a 11 personas por vender pólvora</td>\n",
       "      <td>SAN PEDRO SULA.- Hasta el momento ocho bodegas...</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Con compra de granos se paliaría hambruna en e...</td>\n",
       "      <td>TEGUCIGALPA.- No llueve hace cuatro meses y la...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0    Auditoría revela irregularidades en el Parlacen   \n",
       "1   1          Suspendidas las citas en Hospital Escuela   \n",
       "2   2     Mariscos contaminados alarman a los “porteños”   \n",
       "3   3             Citan a 11 personas por vender pólvora   \n",
       "4   4  Con compra de granos se paliaría hambruna en e...   \n",
       "\n",
       "                                             content  category  \n",
       "0  GUATEMALA.- Una fiscalización de la Contralorí...     Other  \n",
       "1  TEGUCIGALPA.- Una misteriosa obstrucción del s...     Other  \n",
       "2  PUERTO CORTES, Cortés.- Alarmados se encuentra...     Other  \n",
       "3  SAN PEDRO SULA.- Hasta el momento ocho bodegas...  Criminal  \n",
       "4  TEGUCIGALPA.- No llueve hace cuatro meses y la...     Other  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print documents_df.shape\n",
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "## Categories\n",
    "As seen below there are two types of categories: Other and Criminal.  These categories are unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other             1717\n",
       "Criminal           239\n",
       "Criminal-Other      36\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "it seems there are strange objects in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>      1706\n",
      "<type 'float'>     286\n",
      "Name: content, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print documents_df.content.apply(lambda x: type(x) ).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookin further into it we can see that there are NaN objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>La obra de la Línea 1 del Metro de Panamá, el ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>TRIBUNITO DICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>CANTERAS VISTAS DE… ¡REOJO!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>La guerrilla colombiana de las FARC, incorporó...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>HUMORADAS SABATINAS 01/03/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title content category\n",
       "68    68  La obra de la Línea 1 del Metro de Panamá, el ...     NaN    Other\n",
       "91    91                                     TRIBUNITO DICE     NaN    Other\n",
       "114  114                        CANTERAS VISTAS DE… ¡REOJO!     NaN    Other\n",
       "115  115  La guerrilla colombiana de las FARC, incorporó...     NaN    Other\n",
       "117  117                     HUMORADAS SABATINAS 01/03/2014     NaN    Other"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = documents_df.content.apply(lambda x: type(x) == float )\n",
    "documents_df[conditions].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null objects: 286\n"
     ]
    }
   ],
   "source": [
    "print \"null objects: %i\" %documents_df.content.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of those NaN content are there any Criminal categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>Condenan a 40 años de cárcel a 8 pandilleros p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>VUELVEN FEMICIDIOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>269</td>\n",
       "      <td>El director del Infah, aseguró que se le está ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>277</td>\n",
       "      <td>Autoridades hondureñas,  investigarán la muert...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>299</td>\n",
       "      <td>El nuevo gobierno, que ha cumplido un mes en e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>494</td>\n",
       "      <td>Una vecina oyó “gritos terribles” la noche en ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>617</td>\n",
       "      <td>Hasta dos mil 500 millones de lempiras, se pag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>811</td>\n",
       "      <td>Conforman equipo especial para investigar robo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>845</td>\n",
       "      <td>Autoridades hondureñas, han iniciado el proces...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>909</td>\n",
       "      <td>IMPARABLE MUERTE DE BUSEROS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>965</td>\n",
       "      <td>Un revólver, dos celulares y media libra de ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1166</td>\n",
       "      <td>EN EL DÍA DEL PADRE MATA A SU HIJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1289</td>\n",
       "      <td>4 HERIDOS EN BALACERA A BUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1398</td>\n",
       "      <td>CAPTURADA MUJER DE “CHEPE” HANDAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1476</td>\n",
       "      <td>ACOSADOS POR MARAS HUYEN DE COLEGIOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>1712</td>\n",
       "      <td>QUEMADOS VIVOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>1825</td>\n",
       "      <td>ULTIMADOS 3 ESTUDIANTES EN MENOS DE 12 HORAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title content  \\\n",
       "198    198  Condenan a 40 años de cárcel a 8 pandilleros p...     NaN   \n",
       "237    237                                 VUELVEN FEMICIDIOS     NaN   \n",
       "265    269  El director del Infah, aseguró que se le está ...     NaN   \n",
       "273    277  Autoridades hondureñas,  investigarán la muert...     NaN   \n",
       "295    299  El nuevo gobierno, que ha cumplido un mes en e...     NaN   \n",
       "490    494  Una vecina oyó “gritos terribles” la noche en ...     NaN   \n",
       "612    617  Hasta dos mil 500 millones de lempiras, se pag...     NaN   \n",
       "805    811  Conforman equipo especial para investigar robo...     NaN   \n",
       "837    845  Autoridades hondureñas, han iniciado el proces...     NaN   \n",
       "901    909                        IMPARABLE MUERTE DE BUSEROS     NaN   \n",
       "957    965  Un revólver, dos celulares y media libra de ma...     NaN   \n",
       "1158  1166                 EN EL DÍA DEL PADRE MATA A SU HIJO     NaN   \n",
       "1281  1289                        4 HERIDOS EN BALACERA A BUS     NaN   \n",
       "1390  1398                  CAPTURADA MUJER DE “CHEPE” HANDAL     NaN   \n",
       "1468  1476               ACOSADOS POR MARAS HUYEN DE COLEGIOS     NaN   \n",
       "1704  1712                                     QUEMADOS VIVOS     NaN   \n",
       "1817  1825       ULTIMADOS 3 ESTUDIANTES EN MENOS DE 12 HORAS     NaN   \n",
       "\n",
       "      category  \n",
       "198   Criminal  \n",
       "237   Criminal  \n",
       "265   Criminal  \n",
       "273   Criminal  \n",
       "295   Criminal  \n",
       "490   Criminal  \n",
       "612   Criminal  \n",
       "805   Criminal  \n",
       "837   Criminal  \n",
       "901   Criminal  \n",
       "957   Criminal  \n",
       "1158  Criminal  \n",
       "1281  Criminal  \n",
       "1390  Criminal  \n",
       "1468  Criminal  \n",
       "1704  Criminal  \n",
       "1817  Criminal  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df[(documents_df.content.isnull() ) & (documents_df[\"category\"]==\"Criminal\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all NaN\n",
    "even though there are some values of Criminal category, they don't have any more information that will help in the final objective\n",
    "\n",
    "\n",
    "will mantain the original as documents_df\n",
    "The processed is documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title, content, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = documents_df[(documents_df.content.notnull() ) & (documents_df[\"category\"]!=\"Criminal-Other\")]\n",
    "documents[(documents.content.isnull() )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things to consider...\n",
    "\n",
    "- Most common words\n",
    "- Size of text \n",
    "- Numbers of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import wordpunct_tokenize, RegexpTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'_',\n",
       " u'a',\n",
       " u'actualmente',\n",
       " u'acuerdo',\n",
       " u'adelante',\n",
       " u'ademas',\n",
       " u'adem\\xe1s',\n",
       " u'adrede',\n",
       " u'afirm\\xf3',\n",
       " u'agreg\\xf3',\n",
       " u'ahi',\n",
       " u'ahora',\n",
       " u'ah\\xed',\n",
       " u'al',\n",
       " u'algo',\n",
       " u'alguna',\n",
       " u'algunas',\n",
       " u'alguno',\n",
       " u'algunos',\n",
       " u'alg\\xfan']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = pd.read_json(\"../files/stopwords.json\")[0].values.tolist()\n",
    "# len(stop_words)\n",
    "# type(stop_words)\n",
    "# stop_words.tolist()\n",
    "stop_words[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'polic\\xeda', 198)\n",
      "(u'nacional', 175)\n",
      "(u'autoridades', 156)\n",
      "(u'colonia', 152)\n",
      "(u'personas', 138)\n",
      "(u'san', 111)\n",
      "(u'a\\xf1os', 108)\n",
      "(u'armas', 108)\n",
      "(u'honduras', 107)\n",
      "(u'vida', 106)\n",
      "(u'seguridad', 105)\n",
      "(u'zona', 88)\n",
      "(u'centro', 85)\n",
      "(u'pedro', 79)\n",
      "(u'jos\\xe9', 78)\n",
      "(u'sula', 78)\n",
      "(u'policial', 77)\n",
      "(u'p\\xfablico', 72)\n",
      "(u'agentes', 71)\n",
      "(u'crimen', 71)\n",
      "(u'investigaci\\xf3n', 70)\n",
      "(u'casa', 67)\n",
      "(u'pa\\xeds', 66)\n",
      "(u'orden', 65)\n",
      "(u'policiales', 65)\n",
      "(u'tegucigalpa', 63)\n",
      "(u'cort\\xe9s', 63)\n",
      "(u'hern\\xe1ndez', 63)\n",
      "(u'drogas', 63)\n",
      "(u'criminal', 63)\n"
     ]
    }
   ],
   "source": [
    "#most common words\n",
    "\n",
    "\n",
    "full_text = \"\"\n",
    "for index, row in documents.iterrows():\n",
    "    full_text += \" \" + row[\"content\"]\n",
    "    \n",
    "criminal_text = \"\"\n",
    "for index, row in documents[documents[\"category\"] == \"Criminal\"].iterrows():\n",
    "    criminal_text += \" \" + row[\"content\"]   \n",
    "    \n",
    "other_text = \"\"\n",
    "for index, row in documents[documents[\"category\"] == \"Other\"].iterrows():\n",
    "    other_text += \" \" + row[\"content\"]   \n",
    "    \n",
    "    \n",
    "regTokenizer = RegexpTokenizer(r'\\w+')\n",
    "def most_common(text,top=30):\n",
    "    tokens = regTokenizer.tokenize( unicode(text, \"utf-8\").lower() )\n",
    "    tokens = [ token for token in tokens if token not in stop_words]\n",
    "\n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    for w in  fdist.most_common(top):\n",
    "        print w\n",
    "    \n",
    "\n",
    "most_common(criminal_text,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.content.apply(lambda x: len(x) ).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other       1449\n",
       "Criminal     222\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final State of documents\n",
    "documents.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextabora/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:476: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "documents.loc[:,\"content\"] = documents.content.apply(lambda x: unicode(x, \"utf-8\").lower()  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vectorizer1 = CountVectorizer(min_df=1, max_df=1, #max_features=700,  \n",
    "                              analyzer='char_wb', ngram_range=(5, 5),\n",
    "                              stop_words=stop_words, binary=False)\n",
    "# vectorizer1 = TfidfVectorizer(min_df=1,stop_words=stop_words ) #max_features=500\n",
    "vectorizer2 = CountVectorizer(min_df=1, max_df=1,  analyzer='word', stop_words=stop_words, binary=True)\n",
    "# vectorizer2 = TfidfVectorizer(min_df=1,stop_words=stop_words ) \n",
    "\n",
    "\n",
    "#train the vectorizer but only with the positive samples\n",
    "vectorizer1.fit(documents[documents[\"category\"]==\"Criminal\"].content.values)\n",
    "vectorizer2.fit(documents[documents[\"category\"]==\"Criminal\"].title.values)\n",
    "\n",
    "\n",
    "X1 = vectorizer1.transform(documents.content.values)\n",
    "X = vectorizer2.fit_transform(documents.title.values)\n",
    "\n",
    "# X = sp.hstack((X1, X2), format='csr')\n",
    "\n",
    "\n",
    "y = documents.category.apply(lambda x:  int(x==\"Criminal\") ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "- Train Score: 0.9760\n",
      "- Test Score: 0.2418\n",
      "45 of 335 were criminal\n",
      "precision: 1.0000, 0.1307\n",
      "recall: 0.8192, 0.8222\n",
      "f score: 0.9006, 0.2256\n",
      "supoort: 177.0000, 45.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9768\n",
      "- Test Score: 0.2567\n",
      "45 of 335 were criminal\n",
      "precision: 1.0000, 0.1304\n",
      "recall: 0.8249, 0.8000\n",
      "f score: 0.9040, 0.2243\n",
      "supoort: 177.0000, 45.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9768\n",
      "- Test Score: 0.2575\n",
      "44 of 334 were criminal\n",
      "precision: 1.0000, 0.1277\n",
      "recall: 0.8258, 0.7955\n",
      "f score: 0.9046, 0.2201\n",
      "supoort: 178.0000, 44.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9738\n",
      "- Test Score: 0.2425\n",
      "44 of 334 were criminal\n",
      "precision: 1.0000, 0.1359\n",
      "recall: 0.8034, 0.8864\n",
      "f score: 0.8910, 0.2356\n",
      "supoort: 178.0000, 44.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9768\n",
      "- Test Score: 0.2733\n",
      "44 of 333 were criminal\n",
      "precision: 1.0000, 0.1306\n",
      "recall: 0.8258, 0.7955\n",
      "f score: 0.9046, 0.2244\n",
      "supoort: 178.0000, 44.0000\n",
      "\n",
      "avg precision: 0.1311\n",
      "avg recall: 0.8199\n",
      "avg f score: 0.2260\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=943)\n",
    "\n",
    "\n",
    "avg_precision = 0.0\n",
    "avg_recall = 0.0\n",
    "avg_fscore = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    prior = y.sum() *1.0 / len(y)\n",
    "    \n",
    "    clf = MultinomialNB(alpha=.001, class_prior=[1-prior,prior ], fit_prior=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred )) #target_names=target_names\n",
    "    precision_train, recall_train, fscore_train, support_train = precision_recall_fscore_support(y_train,y_pred_train)\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test,y_pred_test)\n",
    "    \n",
    "    print \"---------------------------\"\n",
    "    print \"- Train Score: %0.4f\" % clf.score(X_train, y_train)\n",
    "    print \"- Test Score: %0.4f\" % clf.score(X_test, y_test)\n",
    "    print \"%i of %i were criminal\" % (y_test.sum(), len(y_test))\n",
    "    print \"precision: %0.4f, %0.4f\" % (precision_train[1], precision[1])\n",
    "    print \"recall: %0.4f, %0.4f\" % (recall_train[1], recall[1])\n",
    "    print \"f score: %0.4f, %0.4f\" % (fscore_train[1], fscore[1])\n",
    "    print \"supoort: %0.4f, %0.4f\" % (support_train[1], support[1])\n",
    "    \n",
    "    avg_precision += precision[1]\n",
    "    avg_recall += recall[1]\n",
    "    avg_fscore += fscore[1]\n",
    "    \n",
    "#     break\n",
    "    \n",
    "print \n",
    "print \"avg precision: %0.4f\" %(avg_precision/splits)\n",
    "print \"avg recall: %0.4f\" %(avg_recall/splits)\n",
    "print \"avg f score: %0.4f\" %(avg_fscore/splits)\n",
    "    \n",
    "# clf.fit(X[[0,1,2,3,5,6,7,8,9,10]], y[[0,1,2,3,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO\n",
    "\n",
    "- Add a CV grid search or a Bayes \n",
    "- Think in stacking (one for recall one for precision ;) ) \n",
    "- More data... data exploration...\n",
    "- Try other classifiers...  Logistic, SVC , XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Change of plans\n",
    "\n",
    "Create two classifiers: One optimized for Recall and One optimized for Precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precision_classifier(df, splits=5):\n",
    "    # 0.3\n",
    "    vectorizer1 = CountVectorizer(min_df=1, max_df=0.3, #max_features=700,  \n",
    "#                               analyzer='char_wb', ngram_range=(5, 5),\n",
    "                              stop_words=stop_words, binary=True)\n",
    "    \n",
    "    X = df \n",
    "    y = df.category.apply(lambda x:  int(x==\"Criminal\") ).values\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=943)\n",
    "    avg_score = [0.0,0.0]\n",
    "    avg_precision = [0.0,0.0]\n",
    "    avg_recall = [0.0,0.0]\n",
    "    avg_fscore = [0.0,0.0]\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):   \n",
    "        \n",
    "            \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "                \n",
    "        \n",
    "        vectorizer1.fit(X_train.content[X_train[\"category\"]==\"Criminal\"].values)\n",
    "        X_train = vectorizer1.transform(X_train.content.values)\n",
    "        X_test = vectorizer1.transform(X_test.content.values)\n",
    "        \n",
    "\n",
    "        prior = y_train.sum() *1.0 / len(y_train)\n",
    "\n",
    "        clf = MultinomialNB(alpha=1, class_prior=[1-prior,prior ], fit_prior=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "\n",
    "        #train\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_train,y_pred_train)\n",
    "        avg_score[0] += clf.score(X_train, y_train)\n",
    "        avg_precision[0] += prec[1]\n",
    "        avg_recall[0] += rec[1]\n",
    "        avg_fscore[0] += f1[1]\n",
    "        #test\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_test,y_pred_test)\n",
    "        avg_score[1] += clf.score(X_test, y_test)\n",
    "        avg_precision[1] += prec[1]\n",
    "        avg_recall[1] += rec[1]\n",
    "        avg_fscore[1] += f1[1]\n",
    "        \n",
    "        splits =1.0\n",
    "        break\n",
    "\n",
    "    print \"avg score    : %0.4f, %0.4f\" %(avg_score[0]/splits, avg_score[1]/splits )\n",
    "    print \"avg precision: %0.4f, %0.4f\" %(avg_precision[0]/splits, avg_precision[1]/splits  )\n",
    "    print \"avg recall   : %0.4f, %0.4f\" %(avg_recall[0]/splits, avg_recall[1]/splits )\n",
    "    print \"avg f score  : %0.4f, %0.4f\" %(avg_fscore[0]/splits, avg_fscore[1]/splits  )\n",
    "    \n",
    "    return clf, X_train, y_train, X_test\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score    : 0.9805, 0.9493\n",
      "avg precision: 0.8953, 0.7800\n",
      "avg recall   : 0.9661, 0.8667\n",
      "avg f score  : 0.9293, 0.8211\n"
     ]
    }
   ],
   "source": [
    "clf_prec, X_train_prec, y_train_prec, X_test_prec = precision_classifier(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score    : 0.9746, 0.9522\n",
      "avg precision: 0.8522, 0.7843\n",
      "avg recall   : 0.9774, 0.8889\n",
      "avg f score  : 0.9105, 0.8333\n"
     ]
    }
   ],
   "source": [
    "def recall_classifier(df, splits=5):\n",
    "    #0,9  0.2410\n",
    "    vectorizer1 = CountVectorizer(min_df=1, max_df=0.9, #max_features=700,  \n",
    "                              analyzer='char_wb', ngram_range=(5, 5),\n",
    "                              stop_words=stop_words, binary=True)\n",
    "    vectorizer2 = CountVectorizer(min_df=1, max_df=0.9,  analyzer='word', stop_words=stop_words, binary=True)\n",
    "#     vectorizer2 = TfidfVectorizer(min_df=1,stop_words=stop_words ) \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    X = df\n",
    "    y = df.category.apply(lambda x:  int(x==\"Criminal\") ).values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=943)\n",
    "    avg_score = [0.0,0.0]\n",
    "    avg_precision = [0.0,0.0]\n",
    "    avg_recall = [0.0,0.0]\n",
    "    avg_fscore = [0.0,0.0]\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):    \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        vectorizer1.fit(X_train[X_train[\"category\"]==\"Criminal\"].content.values)\n",
    "        vectorizer2.fit(X_train.title.values)\n",
    "        \n",
    "        X_train1 = vectorizer1.transform(X_train.content.values)\n",
    "        X_train2 = vectorizer2.transform(X_train.title.values)\n",
    "        X_train = sp.hstack((X_train1, X_train2), format='csr')\n",
    "        \n",
    "        X_test1 = vectorizer1.transform(X_test.content.values)\n",
    "        X_test2 = vectorizer2.transform(X_test.title.values)\n",
    "        X_test = sp.hstack((X_test1, X_test2), format='csr')\n",
    "\n",
    "        prior = y.sum() *1.0 / len(y)\n",
    "        #0.001\n",
    "        clf = MultinomialNB(alpha=0.5, class_prior=[1-prior,prior ], fit_prior=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "\n",
    "        #train\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_train,y_pred_train)\n",
    "        avg_score[0] += clf.score(X_train, y_train)\n",
    "        avg_precision[0] += prec[1]\n",
    "        avg_recall[0] += rec[1]\n",
    "        avg_fscore[0] += f1[1]\n",
    "        #test\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_test,y_pred_test)\n",
    "        avg_score[1] += clf.score(X_test, y_test)\n",
    "        avg_precision[1] += prec[1]\n",
    "        avg_recall[1] += rec[1]\n",
    "        avg_fscore[1] += f1[1]\n",
    "        \n",
    "        splits =1.0\n",
    "        break\n",
    "\n",
    "    print \"avg score    : %0.4f, %0.4f\" %(avg_score[0]/splits, avg_score[1]/splits )\n",
    "    print \"avg precision: %0.4f, %0.4f\" %(avg_precision[0]/splits, avg_precision[1]/splits  )\n",
    "    print \"avg recall   : %0.4f, %0.4f\" %(avg_recall[0]/splits, avg_recall[1]/splits )\n",
    "    print \"avg f score  : %0.4f, %0.4f\" %(avg_fscore[0]/splits, avg_fscore[1]/splits  )\n",
    "    \n",
    "    return clf, X_train, y_train, X_test, y_test\n",
    "    \n",
    "    \n",
    "clf_recall, X_train_recall, y_train_recall, X_test_recall, y_test = recall_classifier(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "335\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.97909408,  0.8125    ]),\n",
       " array([ 0.96896552,  0.86666667]),\n",
       " array([ 0.97400347,  0.83870968]),\n",
       " array([290,  45]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf_recall.predict(X_test_recall)\n",
    "print sum(y_pred_test)\n",
    "print len(y_pred_test)\n",
    "print\n",
    "preds = []\n",
    "for index, val in enumerate(y_pred_test):\n",
    "    if val == 0:\n",
    "        preds.append(val)\n",
    "    else:\n",
    "        z = clf_prec.predict(X_test_prec[index])[0]\n",
    "        preds.append(z)\n",
    "\n",
    "\n",
    "precision_recall_fscore_support(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.98245614,  0.8       ]),\n",
       " array([ 0.96551724,  0.88888889]),\n",
       " array([ 0.97391304,  0.84210526]),\n",
       " array([290,  45]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_test_recall = clf_recall.predict_log_proba(X_test_recall)\n",
    "proba_test_prec   = clf_prec.predict_log_proba(X_test_prec)\n",
    "\n",
    "final_preds = []\n",
    "X_test_stacked = []\n",
    "w_rec = .45\n",
    "for rec, prec in zip(proba_test_recall, proba_test_prec):\n",
    "    class0 = (rec[0]*w_rec) + (prec[0]*(1-w_rec))\n",
    "    class1 = (rec[1]*w_rec) + (prec[1]*(1-w_rec))\n",
    "    final_preds.append(int(class1 > class0))\n",
    "    X_test_stacked.append([rec[0],rec[1],prec[0],prec[1]])\n",
    "    \n",
    "    \n",
    "precision_recall_fscore_support(y_test,final_preds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.97269625,  0.88095238]),\n",
       " array([ 0.98275862,  0.82222222]),\n",
       " array([ 0.97770154,  0.85057471]),\n",
       " array([290,  45]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_train_recall = clf_recall.predict_log_proba(X_train_recall)\n",
    "proba_train_prec   = clf_prec.predict_log_proba(X_train_prec)\n",
    "\n",
    "\n",
    "X_train_stacked = []\n",
    "for rec, prec in zip(proba_train_recall, proba_train_prec):\n",
    "    X_train_stacked.append([rec[0],rec[1],prec[0],prec[1]])\n",
    "    \n",
    "    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "\n",
    "rf_clf = rf_clf.fit(X_train_stacked, y_train_recall)\n",
    "\n",
    "stacked_preds = rf_clf.predict(X_test_stacked)\n",
    "precision_recall_fscore_support(y_test,stacked_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "335\n"
     ]
    }
   ],
   "source": [
    "print sum(stacked_preds)\n",
    "print len(stacked_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.95959596,  0.86842105]),\n",
       " array([ 0.98275862,  0.73333333]),\n",
       " array([ 0.97103918,  0.79518072]),\n",
       " array([290,  45]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(C=1, max_iter=600)\n",
    "log_clf = log_clf.fit(X_train_stacked, y_train_recall)\n",
    "\n",
    "stacked_preds = log_clf.predict(X_test_stacked)\n",
    "precision_recall_fscore_support(y_test,stacked_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
