{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook is to test the classifier.\n",
    "It will involve a little of data exploration, feature extraction using bag of words and training a classifier. \n",
    "\n",
    "Later the code will be codified into python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_df = pd.read_csv(\"../files/documents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Auditoría revela irregularidades en el Parlacen</td>\n",
       "      <td>GUATEMALA.- Una fiscalización de la Contralorí...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Suspendidas las citas en Hospital Escuela</td>\n",
       "      <td>TEGUCIGALPA.- Una misteriosa obstrucción del s...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mariscos contaminados alarman a los “porteños”</td>\n",
       "      <td>PUERTO CORTES, Cortés.- Alarmados se encuentra...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Citan a 11 personas por vender pólvora</td>\n",
       "      <td>SAN PEDRO SULA.- Hasta el momento ocho bodegas...</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Con compra de granos se paliaría hambruna en e...</td>\n",
       "      <td>TEGUCIGALPA.- No llueve hace cuatro meses y la...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0    Auditoría revela irregularidades en el Parlacen   \n",
       "1   1          Suspendidas las citas en Hospital Escuela   \n",
       "2   2     Mariscos contaminados alarman a los “porteños”   \n",
       "3   3             Citan a 11 personas por vender pólvora   \n",
       "4   4  Con compra de granos se paliaría hambruna en e...   \n",
       "\n",
       "                                             content  category  \n",
       "0  GUATEMALA.- Una fiscalización de la Contralorí...     Other  \n",
       "1  TEGUCIGALPA.- Una misteriosa obstrucción del s...     Other  \n",
       "2  PUERTO CORTES, Cortés.- Alarmados se encuentra...     Other  \n",
       "3  SAN PEDRO SULA.- Hasta el momento ocho bodegas...  Criminal  \n",
       "4  TEGUCIGALPA.- No llueve hace cuatro meses y la...     Other  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print documents_df.shape\n",
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "## Categories\n",
    "As seen below there are two types of categories: Other and Criminal.  These categories are unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other             1715\n",
       "Criminal           243\n",
       "Criminal-Other      34\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "it seems there are strange objects in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>      1702\n",
      "<type 'float'>     290\n",
      "Name: content, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print documents_df.content.apply(lambda x: type(x) ).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookin further into it we can see that there are NaN objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>La obra de la Línea 1 del Metro de Panamá, el ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>TRIBUNITO DICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>CANTERAS VISTAS DE… ¡REOJO!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>La guerrilla colombiana de las FARC, incorporó...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>HUMORADAS SABATINAS 01/03/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title content category\n",
       "68    68  La obra de la Línea 1 del Metro de Panamá, el ...     NaN    Other\n",
       "91    91                                     TRIBUNITO DICE     NaN    Other\n",
       "114  114                        CANTERAS VISTAS DE… ¡REOJO!     NaN    Other\n",
       "115  115  La guerrilla colombiana de las FARC, incorporó...     NaN    Other\n",
       "117  117                     HUMORADAS SABATINAS 01/03/2014     NaN    Other"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = documents_df.content.apply(lambda x: type(x) == float )\n",
    "documents_df[conditions].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null objects: 290\n"
     ]
    }
   ],
   "source": [
    "print \"null objects: %i\" %documents_df.content.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of those NaN content are there any Criminal categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>Condenan a 40 años de cárcel a 8 pandilleros p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>VUELVEN FEMICIDIOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>La Asociación de Jueces y Magistrados, pide tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>“12 Years a Slave” se proclama mejor película ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>Autoridades de Copeco, reportaron hoy 90 incen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>Honduras, a las puertas de un acuerdo con el F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>Centro de Atención a mujeres víctimas de viole...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>El Gobierno de Kiev, arropado por Occidente, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>El aire acondicionado hace tiritar la economía...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>Una vecina oyó “gritos terribles” la noche en ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>627</td>\n",
       "      <td>Consejo de la Judicatura, nombra más de una ve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>Putin rompe su silencio para advertir de que a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>702</td>\n",
       "      <td>LEY DE DERRIBOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>813</td>\n",
       "      <td>Fuerza Nacional de Seguridad Interinstituciona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>830</td>\n",
       "      <td>115 millones de lempiras anuales, dejarán de p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>A 22 millones de dólares, podría ascender coop...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>Un monasterio reza entre el fuego cruzado en S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>Consumidores de pollo en Honduras, denuncian i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>953</td>\n",
       "      <td>800 millones de lempiras, ahorra Estado con re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>957</td>\n",
       "      <td>Sólo cinco alcaldías del país tienen su portal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>963</td>\n",
       "      <td>Zona norte hondureña, presenta problemas de ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1166</td>\n",
       "      <td>EN EL DÍA DEL PADRE MATA A SU HIJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1615</td>\n",
       "      <td>TRIBUNITO DICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>1726</td>\n",
       "      <td>OTRA “RIGIOSA”</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1967</td>\n",
       "      <td>TALLER AMBULANTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title content  \\\n",
       "198    198  Condenan a 40 años de cárcel a 8 pandilleros p...     NaN   \n",
       "237    237                                 VUELVEN FEMICIDIOS     NaN   \n",
       "297    297  La Asociación de Jueces y Magistrados, pide tr...     NaN   \n",
       "349    349  “12 Years a Slave” se proclama mejor película ...     NaN   \n",
       "430    430  Autoridades de Copeco, reportaron hoy 90 incen...     NaN   \n",
       "437    437  Honduras, a las puertas de un acuerdo con el F...     NaN   \n",
       "465    465  Centro de Atención a mujeres víctimas de viole...     NaN   \n",
       "475    475  El Gobierno de Kiev, arropado por Occidente, d...     NaN   \n",
       "490    490  El aire acondicionado hace tiritar la economía...     NaN   \n",
       "494    494  Una vecina oyó “gritos terribles” la noche en ...     NaN   \n",
       "627    627  Consejo de la Judicatura, nombra más de una ve...     NaN   \n",
       "662    662  Putin rompe su silencio para advertir de que a...     NaN   \n",
       "702    702                                    LEY DE DERRIBOS     NaN   \n",
       "813    813  Fuerza Nacional de Seguridad Interinstituciona...     NaN   \n",
       "830    830  115 millones de lempiras anuales, dejarán de p...     NaN   \n",
       "835    835  A 22 millones de dólares, podría ascender coop...     NaN   \n",
       "934    934  Un monasterio reza entre el fuego cruzado en S...     NaN   \n",
       "938    938  Consumidores de pollo en Honduras, denuncian i...     NaN   \n",
       "953    953  800 millones de lempiras, ahorra Estado con re...     NaN   \n",
       "957    957  Sólo cinco alcaldías del país tienen su portal...     NaN   \n",
       "963    963  Zona norte hondureña, presenta problemas de ba...     NaN   \n",
       "1166  1166                 EN EL DÍA DEL PADRE MATA A SU HIJO     NaN   \n",
       "1615  1615                                     TRIBUNITO DICE     NaN   \n",
       "1726  1726                                     OTRA “RIGIOSA”     NaN   \n",
       "1967  1967                                   TALLER AMBULANTE     NaN   \n",
       "\n",
       "      category  \n",
       "198   Criminal  \n",
       "237   Criminal  \n",
       "297   Criminal  \n",
       "349   Criminal  \n",
       "430   Criminal  \n",
       "437   Criminal  \n",
       "465   Criminal  \n",
       "475   Criminal  \n",
       "490   Criminal  \n",
       "494   Criminal  \n",
       "627   Criminal  \n",
       "662   Criminal  \n",
       "702   Criminal  \n",
       "813   Criminal  \n",
       "830   Criminal  \n",
       "835   Criminal  \n",
       "934   Criminal  \n",
       "938   Criminal  \n",
       "953   Criminal  \n",
       "957   Criminal  \n",
       "963   Criminal  \n",
       "1166  Criminal  \n",
       "1615  Criminal  \n",
       "1726  Criminal  \n",
       "1967  Criminal  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df[(documents_df.content.isnull() ) & (documents_df[\"category\"]==\"Criminal\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condenan a 40 años de cárcel a 8 pandilleros por crimen de joven deportista.\n"
     ]
    }
   ],
   "source": [
    "print documents_df.loc[198].title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all NaN\n",
    "even though there are some values of Criminal category, they don't have any more information that will help in the final objective\n",
    "\n",
    "\n",
    "will mantain the original as documents_df\n",
    "The processed is documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title, content, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = documents_df[(documents_df.content.notnull() ) & (documents_df[\"category\"]!=\"Criminal-Other\")]\n",
    "documents[(documents.content.isnull() )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things to consider...\n",
    "\n",
    "- Most common words\n",
    "- Size of text \n",
    "- Numbers of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import wordpunct_tokenize, RegexpTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0',\n",
       " u'1',\n",
       " u'2',\n",
       " u'3',\n",
       " u'4',\n",
       " u'5',\n",
       " u'6',\n",
       " u'7',\n",
       " u'8',\n",
       " u'9',\n",
       " u'_',\n",
       " u'a',\n",
       " u'actualmente',\n",
       " u'acuerdo',\n",
       " u'adelante',\n",
       " u'ademas',\n",
       " u'adem\\xe1s',\n",
       " u'adrede',\n",
       " u'afirm\\xf3',\n",
       " u'agreg\\xf3',\n",
       " u'ahi',\n",
       " u'ahora',\n",
       " u'ah\\xed',\n",
       " u'al',\n",
       " u'algo',\n",
       " u'alguna',\n",
       " u'algunas',\n",
       " u'alguno',\n",
       " u'algunos',\n",
       " u'alg\\xfan',\n",
       " u'alli',\n",
       " u'all\\xed',\n",
       " u'alrededor',\n",
       " u'ambos',\n",
       " u'ampleamos',\n",
       " u'antano',\n",
       " u'anta\\xf1o',\n",
       " u'ante',\n",
       " u'anterior',\n",
       " u'antes',\n",
       " u'apenas',\n",
       " u'aproximadamente',\n",
       " u'aquel',\n",
       " u'aquella',\n",
       " u'aquellas',\n",
       " u'aquello',\n",
       " u'aquellos',\n",
       " u'aqui',\n",
       " u'aqu\\xe9l',\n",
       " u'aqu\\xe9lla',\n",
       " u'aqu\\xe9llas',\n",
       " u'aqu\\xe9llos',\n",
       " u'aqu\\xed',\n",
       " u'arriba',\n",
       " u'arribaabajo',\n",
       " u'asegur\\xf3',\n",
       " u'asi',\n",
       " u'as\\xed',\n",
       " u'atras',\n",
       " u'aun',\n",
       " u'aunque',\n",
       " u'ayer',\n",
       " u'a\\xf1adi\\xf3',\n",
       " u'a\\xfan',\n",
       " u'b',\n",
       " u'bajo',\n",
       " u'bastante',\n",
       " u'bien',\n",
       " u'breve',\n",
       " u'buen',\n",
       " u'buena',\n",
       " u'buenas',\n",
       " u'bueno',\n",
       " u'buenos',\n",
       " u'c',\n",
       " u'cada',\n",
       " u'casi',\n",
       " u'cerca',\n",
       " u'cierta',\n",
       " u'ciertas',\n",
       " u'cierto',\n",
       " u'ciertos',\n",
       " u'cinco',\n",
       " u'claro',\n",
       " u'coment\\xf3',\n",
       " u'como',\n",
       " u'con',\n",
       " u'conmigo',\n",
       " u'conocer',\n",
       " u'conseguimos',\n",
       " u'conseguir',\n",
       " u'considera',\n",
       " u'consider\\xf3',\n",
       " u'consigo',\n",
       " u'consigue',\n",
       " u'consiguen',\n",
       " u'consigues',\n",
       " u'contigo',\n",
       " u'contra',\n",
       " u'cosas',\n",
       " u'creo',\n",
       " u'cual',\n",
       " u'cuales',\n",
       " u'cualquier',\n",
       " u'cuando',\n",
       " u'cuanta',\n",
       " u'cuantas',\n",
       " u'cuanto',\n",
       " u'cuantos',\n",
       " u'cuatro',\n",
       " u'cuenta',\n",
       " u'cu\\xe1l',\n",
       " u'cu\\xe1les',\n",
       " u'cu\\xe1ndo',\n",
       " u'cu\\xe1nta',\n",
       " u'cu\\xe1ntas',\n",
       " u'cu\\xe1nto',\n",
       " u'cu\\xe1ntos',\n",
       " u'c\\xf3mo',\n",
       " u'd',\n",
       " u'da',\n",
       " u'dado',\n",
       " u'dan',\n",
       " u'dar',\n",
       " u'de',\n",
       " u'debajo',\n",
       " u'debe',\n",
       " u'deben',\n",
       " u'debido',\n",
       " u'decir',\n",
       " u'dej\\xf3',\n",
       " u'del',\n",
       " u'delante',\n",
       " u'demasiado',\n",
       " u'dem\\xe1s',\n",
       " u'dentro',\n",
       " u'deprisa',\n",
       " u'desde',\n",
       " u'despacio',\n",
       " u'despues',\n",
       " u'despu\\xe9s',\n",
       " u'detras',\n",
       " u'detr\\xe1s',\n",
       " u'dia',\n",
       " u'dias',\n",
       " u'dice',\n",
       " u'dicen',\n",
       " u'dicho',\n",
       " u'dieron',\n",
       " u'diferente',\n",
       " u'diferentes',\n",
       " u'dijeron',\n",
       " u'dijo',\n",
       " u'dio',\n",
       " u'donde',\n",
       " u'dos',\n",
       " u'durante',\n",
       " u'd\\xeda',\n",
       " u'd\\xedas',\n",
       " u'd\\xf3nde',\n",
       " u'e',\n",
       " u'ejemplo',\n",
       " u'el',\n",
       " u'ella',\n",
       " u'ellas',\n",
       " u'ello',\n",
       " u'ellos',\n",
       " u'embargo',\n",
       " u'empleais',\n",
       " u'emplean',\n",
       " u'emplear',\n",
       " u'empleas',\n",
       " u'empleo',\n",
       " u'en',\n",
       " u'encima',\n",
       " u'encuentra',\n",
       " u'enfrente',\n",
       " u'enseguida',\n",
       " u'entonces',\n",
       " u'entre',\n",
       " u'era',\n",
       " u'erais',\n",
       " u'eramos',\n",
       " u'eran',\n",
       " u'eras',\n",
       " u'eres',\n",
       " u'es',\n",
       " u'esa',\n",
       " u'esas',\n",
       " u'ese',\n",
       " u'eso',\n",
       " u'esos',\n",
       " u'esta',\n",
       " u'estaba',\n",
       " u'estabais',\n",
       " u'estaban',\n",
       " u'estabas',\n",
       " u'estad',\n",
       " u'estada',\n",
       " u'estadas',\n",
       " u'estado',\n",
       " u'estados',\n",
       " u'estais',\n",
       " u'estamos',\n",
       " u'estan',\n",
       " u'estando',\n",
       " u'estar',\n",
       " u'estaremos',\n",
       " u'estar\\xe1',\n",
       " u'estar\\xe1n',\n",
       " u'estar\\xe1s',\n",
       " u'estar\\xe9',\n",
       " u'estar\\xe9is',\n",
       " u'estar\\xeda',\n",
       " u'estar\\xedais',\n",
       " u'estar\\xedamos',\n",
       " u'estar\\xedan',\n",
       " u'estar\\xedas',\n",
       " u'estas',\n",
       " u'este',\n",
       " u'estemos',\n",
       " u'esto',\n",
       " u'estos',\n",
       " u'estoy',\n",
       " u'estuve',\n",
       " u'estuviera',\n",
       " u'estuvierais',\n",
       " u'estuvieran',\n",
       " u'estuvieras',\n",
       " u'estuvieron',\n",
       " u'estuviese',\n",
       " u'estuvieseis',\n",
       " u'estuviesen',\n",
       " u'estuvieses',\n",
       " u'estuvimos',\n",
       " u'estuviste',\n",
       " u'estuvisteis',\n",
       " u'estuvi\\xe9ramos',\n",
       " u'estuvi\\xe9semos',\n",
       " u'estuvo',\n",
       " u'est\\xe1',\n",
       " u'est\\xe1bamos',\n",
       " u'est\\xe1is',\n",
       " u'est\\xe1n',\n",
       " u'est\\xe1s',\n",
       " u'est\\xe9',\n",
       " u'est\\xe9is',\n",
       " u'est\\xe9n',\n",
       " u'est\\xe9s',\n",
       " u'ex',\n",
       " u'excepto',\n",
       " u'existe',\n",
       " u'existen',\n",
       " u'explic\\xf3',\n",
       " u'expres\\xf3',\n",
       " u'f',\n",
       " u'fin',\n",
       " u'final',\n",
       " u'fue',\n",
       " u'fuera',\n",
       " u'fuerais',\n",
       " u'fueran',\n",
       " u'fueras',\n",
       " u'fueron',\n",
       " u'fuese',\n",
       " u'fueseis',\n",
       " u'fuesen',\n",
       " u'fueses',\n",
       " u'fui',\n",
       " u'fuimos',\n",
       " u'fuiste',\n",
       " u'fuisteis',\n",
       " u'fu\\xe9ramos',\n",
       " u'fu\\xe9semos',\n",
       " u'g',\n",
       " u'general',\n",
       " u'gran',\n",
       " u'grandes',\n",
       " u'gueno',\n",
       " u'h',\n",
       " u'ha',\n",
       " u'haber',\n",
       " u'habia',\n",
       " u'habida',\n",
       " u'habidas',\n",
       " u'habido',\n",
       " u'habidos',\n",
       " u'habiendo',\n",
       " u'habla',\n",
       " u'hablan',\n",
       " u'habremos',\n",
       " u'habr\\xe1',\n",
       " u'habr\\xe1n',\n",
       " u'habr\\xe1s',\n",
       " u'habr\\xe9',\n",
       " u'habr\\xe9is',\n",
       " u'habr\\xeda',\n",
       " u'habr\\xedais',\n",
       " u'habr\\xedamos',\n",
       " u'habr\\xedan',\n",
       " u'habr\\xedas',\n",
       " u'hab\\xe9is',\n",
       " u'hab\\xeda',\n",
       " u'hab\\xedais',\n",
       " u'hab\\xedamos',\n",
       " u'hab\\xedan',\n",
       " u'hab\\xedas',\n",
       " u'hace',\n",
       " u'haceis',\n",
       " u'hacemos',\n",
       " u'hacen',\n",
       " u'hacer',\n",
       " u'hacerlo',\n",
       " u'haces',\n",
       " u'hacia',\n",
       " u'haciendo',\n",
       " u'hago',\n",
       " u'han',\n",
       " u'has',\n",
       " u'hasta',\n",
       " u'hay',\n",
       " u'haya',\n",
       " u'hayamos',\n",
       " u'hayan',\n",
       " u'hayas',\n",
       " u'hay\\xe1is',\n",
       " u'he',\n",
       " u'hecho',\n",
       " u'hemos',\n",
       " u'hicieron',\n",
       " u'hizo',\n",
       " u'horas',\n",
       " u'hoy',\n",
       " u'hube',\n",
       " u'hubiera',\n",
       " u'hubierais',\n",
       " u'hubieran',\n",
       " u'hubieras',\n",
       " u'hubieron',\n",
       " u'hubiese',\n",
       " u'hubieseis',\n",
       " u'hubiesen',\n",
       " u'hubieses',\n",
       " u'hubimos',\n",
       " u'hubiste',\n",
       " u'hubisteis',\n",
       " u'hubi\\xe9ramos',\n",
       " u'hubi\\xe9semos',\n",
       " u'hubo',\n",
       " u'i',\n",
       " u'igual',\n",
       " u'incluso',\n",
       " u'indic\\xf3',\n",
       " u'informo',\n",
       " u'inform\\xf3',\n",
       " u'intenta',\n",
       " u'intentais',\n",
       " u'intentamos',\n",
       " u'intentan',\n",
       " u'intentar',\n",
       " u'intentas',\n",
       " u'intento',\n",
       " u'ir',\n",
       " u'j',\n",
       " u'junto',\n",
       " u'k',\n",
       " u'l',\n",
       " u'la',\n",
       " u'lado',\n",
       " u'largo',\n",
       " u'las',\n",
       " u'le',\n",
       " u'lejos',\n",
       " u'les',\n",
       " u'lleg\\xf3',\n",
       " u'lleva',\n",
       " u'llevar',\n",
       " u'lo',\n",
       " u'los',\n",
       " u'luego',\n",
       " u'lugar',\n",
       " u'm',\n",
       " u'mal',\n",
       " u'manera',\n",
       " u'manifest\\xf3',\n",
       " u'mas',\n",
       " u'mayor',\n",
       " u'me',\n",
       " u'mediante',\n",
       " u'medio',\n",
       " u'mejor',\n",
       " u'mencion\\xf3',\n",
       " u'menos',\n",
       " u'menudo',\n",
       " u'mi',\n",
       " u'mia',\n",
       " u'mias',\n",
       " u'mientras',\n",
       " u'mio',\n",
       " u'mios',\n",
       " u'mis',\n",
       " u'misma',\n",
       " u'mismas',\n",
       " u'mismo',\n",
       " u'mismos',\n",
       " u'modo',\n",
       " u'momento',\n",
       " u'mucha',\n",
       " u'muchas',\n",
       " u'mucho',\n",
       " u'muchos',\n",
       " u'muy',\n",
       " u'm\\xe1s',\n",
       " u'm\\xed',\n",
       " u'm\\xeda',\n",
       " u'm\\xedas',\n",
       " u'm\\xedo',\n",
       " u'm\\xedos',\n",
       " u'n',\n",
       " u'nada',\n",
       " u'nadie',\n",
       " u'ni',\n",
       " u'ninguna',\n",
       " u'ningunas',\n",
       " u'ninguno',\n",
       " u'ningunos',\n",
       " u'ning\\xfan',\n",
       " u'no',\n",
       " u'nos',\n",
       " u'nosotras',\n",
       " u'nosotros',\n",
       " u'nuestra',\n",
       " u'nuestras',\n",
       " u'nuestro',\n",
       " u'nuestros',\n",
       " u'nueva',\n",
       " u'nuevas',\n",
       " u'nuevo',\n",
       " u'nuevos',\n",
       " u'nunca',\n",
       " u'o',\n",
       " u'ocho',\n",
       " u'os',\n",
       " u'otra',\n",
       " u'otras',\n",
       " u'otro',\n",
       " u'otros',\n",
       " u'p',\n",
       " u'pais',\n",
       " u'para',\n",
       " u'parece',\n",
       " u'parte',\n",
       " u'partir',\n",
       " u'pasada',\n",
       " u'pasado',\n",
       " u'pa\\xecs',\n",
       " u'peor',\n",
       " u'pero',\n",
       " u'pesar',\n",
       " u'poca',\n",
       " u'pocas',\n",
       " u'poco',\n",
       " u'pocos',\n",
       " u'podeis',\n",
       " u'podemos',\n",
       " u'poder',\n",
       " u'podria',\n",
       " u'podriais',\n",
       " u'podriamos',\n",
       " u'podrian',\n",
       " u'podrias',\n",
       " u'podr\\xe1',\n",
       " u'podr\\xe1n',\n",
       " u'podr\\xeda',\n",
       " u'podr\\xedan',\n",
       " u'poner',\n",
       " u'por',\n",
       " u'por qu\\xe9',\n",
       " u'porque',\n",
       " u'posible',\n",
       " u'primer',\n",
       " u'primera',\n",
       " u'primero',\n",
       " u'primeros',\n",
       " u'principalmente',\n",
       " u'pronto',\n",
       " u'propia',\n",
       " u'propias',\n",
       " u'propio',\n",
       " u'propios',\n",
       " u'proximo',\n",
       " u'pr\\xf3ximo',\n",
       " u'pr\\xf3ximos',\n",
       " u'pudo',\n",
       " u'pueda',\n",
       " u'puede',\n",
       " u'pueden',\n",
       " u'puedo',\n",
       " u'pues',\n",
       " u'q',\n",
       " u'qeu',\n",
       " u'que',\n",
       " u'qued\\xf3',\n",
       " u'queremos',\n",
       " u'quien',\n",
       " u'quienes',\n",
       " u'quiere',\n",
       " u'quiza',\n",
       " u'quizas',\n",
       " u'quiz\\xe1',\n",
       " u'quiz\\xe1s',\n",
       " u'qui\\xe9n',\n",
       " u'qui\\xe9nes',\n",
       " u'qu\\xe9',\n",
       " u'r',\n",
       " u'raras',\n",
       " u'realizado',\n",
       " u'realizar',\n",
       " u'realiz\\xf3',\n",
       " u'repente',\n",
       " u'respecto',\n",
       " u's',\n",
       " u'sabe',\n",
       " u'sabeis',\n",
       " u'sabemos',\n",
       " u'saben',\n",
       " u'saber',\n",
       " u'sabes',\n",
       " u'sal',\n",
       " u'salvo',\n",
       " u'se',\n",
       " u'sea',\n",
       " u'seamos',\n",
       " u'sean',\n",
       " u'seas',\n",
       " u'segun',\n",
       " u'segunda',\n",
       " u'segundo',\n",
       " u'seg\\xfan',\n",
       " u'seis',\n",
       " u'ser',\n",
       " u'sera',\n",
       " u'seremos',\n",
       " u'ser\\xe1',\n",
       " u'ser\\xe1n',\n",
       " u'ser\\xe1s',\n",
       " u'ser\\xe9',\n",
       " u'ser\\xe9is',\n",
       " u'ser\\xeda',\n",
       " u'ser\\xedais',\n",
       " u'ser\\xedamos',\n",
       " u'ser\\xedan',\n",
       " u'ser\\xedas',\n",
       " u'se\\xe1is',\n",
       " u'se\\xf1al\\xf3',\n",
       " u'si',\n",
       " u'sido',\n",
       " u'siempre',\n",
       " u'siendo',\n",
       " u'siete',\n",
       " u'sigue',\n",
       " u'siguiente',\n",
       " u'sin',\n",
       " u'sino',\n",
       " u'sobre',\n",
       " u'sois',\n",
       " u'sola',\n",
       " u'solamente',\n",
       " u'solas',\n",
       " u'solo',\n",
       " u'solos',\n",
       " u'somos',\n",
       " u'son',\n",
       " u'soy',\n",
       " u'soyos',\n",
       " u'su',\n",
       " u'supuesto',\n",
       " u'sus',\n",
       " u'suya',\n",
       " u'suyas',\n",
       " u'suyo',\n",
       " u'suyos',\n",
       " u's\\xe9',\n",
       " u's\\xed',\n",
       " u's\\xf3lo',\n",
       " u't',\n",
       " u'tal',\n",
       " u'tambien',\n",
       " u'tambi\\xe9n',\n",
       " u'tampoco',\n",
       " u'tan',\n",
       " u'tanto',\n",
       " u'tarde',\n",
       " u'te',\n",
       " u'temprano',\n",
       " u'tendremos',\n",
       " u'tendr\\xe1',\n",
       " u'tendr\\xe1n',\n",
       " u'tendr\\xe1s',\n",
       " u'tendr\\xe9',\n",
       " u'tendr\\xe9is',\n",
       " u'tendr\\xeda',\n",
       " u'tendr\\xedais',\n",
       " u'tendr\\xedamos',\n",
       " u'tendr\\xedan',\n",
       " u'tendr\\xedas',\n",
       " u'tened',\n",
       " u'teneis',\n",
       " u'tenemos',\n",
       " u'tener',\n",
       " u'tenga',\n",
       " u'tengamos',\n",
       " u'tengan',\n",
       " u'tengas',\n",
       " u'tengo',\n",
       " u'teng\\xe1is',\n",
       " u'tenida',\n",
       " u'tenidas',\n",
       " u'tenido',\n",
       " u'tenidos',\n",
       " u'teniendo',\n",
       " u'ten\\xe9is',\n",
       " u'ten\\xeda',\n",
       " u'ten\\xedais',\n",
       " u'ten\\xedamos',\n",
       " u'ten\\xedan',\n",
       " u'ten\\xedas',\n",
       " u'tercera',\n",
       " u'ti',\n",
       " u'tiempo',\n",
       " u'tiene',\n",
       " u'tienen',\n",
       " u'tienes',\n",
       " u'toda',\n",
       " u'todas',\n",
       " u'todavia',\n",
       " u'todav\\xeda',\n",
       " u'todo',\n",
       " u'todos',\n",
       " u'total',\n",
       " u'trabaja',\n",
       " u'trabajais',\n",
       " u'trabajamos',\n",
       " u'trabajan',\n",
       " u'trabajar',\n",
       " u'trabajas',\n",
       " u'trabajo',\n",
       " u'tras',\n",
       " u'trata',\n",
       " u'trav\\xe9s',\n",
       " u'tres',\n",
       " u'tu',\n",
       " u'tus',\n",
       " u'tuve',\n",
       " u'tuviera',\n",
       " u'tuvierais',\n",
       " u'tuvieran',\n",
       " u'tuvieras',\n",
       " u'tuvieron',\n",
       " u'tuviese',\n",
       " u'tuvieseis',\n",
       " u'tuviesen',\n",
       " u'tuvieses',\n",
       " u'tuvimos',\n",
       " u'tuviste',\n",
       " u'tuvisteis',\n",
       " u'tuvi\\xe9ramos',\n",
       " u'tuvi\\xe9semos',\n",
       " u'tuvo',\n",
       " u'tuya',\n",
       " u'tuyas',\n",
       " u'tuyo',\n",
       " u'tuyos',\n",
       " u't\\xfa',\n",
       " u'u',\n",
       " u'ultimo',\n",
       " u'un',\n",
       " u'una',\n",
       " u'unas',\n",
       " u'uno',\n",
       " u'unos',\n",
       " u'usa',\n",
       " u'usais',\n",
       " u'usamos',\n",
       " u'usan',\n",
       " u'usar',\n",
       " u'usas',\n",
       " u'uso',\n",
       " u'usted',\n",
       " u'ustedes',\n",
       " u'v',\n",
       " u'va',\n",
       " u'vais',\n",
       " u'valor',\n",
       " u'vamos',\n",
       " u'van',\n",
       " u'varias',\n",
       " u'varios',\n",
       " u'vaya',\n",
       " u'veces',\n",
       " u'ver',\n",
       " u'verdad',\n",
       " u'verdadera',\n",
       " u'verdadero',\n",
       " u'vez',\n",
       " u'vosotras',\n",
       " u'vosotros',\n",
       " u'voy',\n",
       " u'vuestra',\n",
       " u'vuestras',\n",
       " u'vuestro',\n",
       " u'vuestros',\n",
       " u'w',\n",
       " u'x',\n",
       " u'y',\n",
       " u'ya',\n",
       " u'yo',\n",
       " u'z',\n",
       " u'\\xe9l',\n",
       " u'\\xe9ramos',\n",
       " u'\\xe9sa',\n",
       " u'\\xe9sas',\n",
       " u'\\xe9se',\n",
       " u'\\xe9sos',\n",
       " u'\\xe9sta',\n",
       " u'\\xe9stas',\n",
       " u'\\xe9ste',\n",
       " u'\\xe9stos',\n",
       " u'\\xfaltima',\n",
       " u'\\xfaltimas',\n",
       " u'\\xfaltimo',\n",
       " u'\\xfaltimos']"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = pd.read_json(\"../files/stopwords.json\")[0].values.tolist()\n",
    "# len(stop_words)\n",
    "# type(stop_words)\n",
    "# stop_words.tolist()\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextabora/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\xe2', 759)\n",
      "('m\\xc3', 262)\n",
      "('\\xc2', 219)\n",
      "('est\\xc3', 214)\n",
      "('\\xc3', 208)\n",
      "('a\\xc3', 184)\n",
      "('nacional', 165)\n",
      "('as', 146)\n",
      "('tambi\\xc3', 125)\n",
      "('honduras', 125)\n",
      "('ni\\xc3', 123)\n",
      "('polic\\xc3', 123)\n",
      "('d\\xc3', 117)\n",
      "('pa\\xc3', 114)\n",
      "('an', 108)\n",
      "('seg\\xc3\\xban', 106)\n",
      "('personas', 104)\n",
      "('presidente', 92)\n",
      "('ser\\xc3', 90)\n",
      "('hondure\\xc3', 88)\n",
      "('san', 88)\n",
      "('vida', 86)\n",
      "('hab\\xc3', 84)\n",
      "('gobierno', 83)\n",
      "('seguridad', 82)\n",
      "('v\\xc3', 72)\n",
      "('c\\xc3', 71)\n",
      "('autoridades', 71)\n",
      "('pol\\xc3', 70)\n",
      "('as\\xc3', 60)\n"
     ]
    }
   ],
   "source": [
    "#most common words\n",
    "\n",
    "\n",
    "full_text = \"\"\n",
    "for index, row in documents.iterrows():\n",
    "    full_text += \" \" + row[\"content\"]\n",
    "    \n",
    "criminal_text = \"\"\n",
    "for index, row in documents[documents[\"category\"] == \"Criminal\"].iterrows():\n",
    "    criminal_text += \" \" + row[\"content\"]   \n",
    "    \n",
    "other_text = \"\"\n",
    "for index, row in documents[documents[\"category\"] == \"Other\"].iterrows():\n",
    "    other_text += \" \" + row[\"content\"]   \n",
    "    \n",
    "    \n",
    "regTokenizer = RegexpTokenizer(r'\\w+')\n",
    "def most_common(text,top=30):\n",
    "    tokens = regTokenizer.tokenize( text.lower() )\n",
    "    tokens = [ token for token in tokens if token not in stop_words]\n",
    "\n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    for w in  fdist.most_common(top):\n",
    "        print w\n",
    "    \n",
    "\n",
    "most_common(criminal_text,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.content.apply(lambda x: len(x) ).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other       1453\n",
       "Criminal     218\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final State of documents\n",
    "documents.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df=1, max_df=1, #max_features=700,  \n",
    "                              analyzer='char_wb', ngram_range=(5, 5),\n",
    "                              stop_words=stop_words, binary=False)\n",
    "# vectorizer1 = TfidfVectorizer(min_df=1,stop_words=stop_words ) #max_features=500\n",
    "vectorizer2 = CountVectorizer(min_df=1, max_df=1,  analyzer='word', stop_words=stop_words, binary=True)\n",
    "# vectorizer2 = TfidfVectorizer(min_df=1,stop_words=stop_words ) \n",
    "\n",
    "\n",
    "#train the vectorizer but only with the positive samples\n",
    "vectorizer1.fit(documents[documents[\"category\"]==\"Criminal\"].content.values)\n",
    "vectorizer2.fit(documents[documents[\"category\"]==\"Criminal\"].title.values)\n",
    "\n",
    "\n",
    "X1 = vectorizer1.transform(documents.content.values)\n",
    "X2 = vectorizer2.fit_transform(documents.title.values)\n",
    "\n",
    "X = sp.hstack((X1, X2), format='csr')\n",
    "\n",
    "\n",
    "y = documents.category.apply(lambda x:  int(x==\"Criminal\") ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "- Train Score: 0.9693\n",
      "- Test Score: 0.8746\n",
      "44 of 335 were criminal\n",
      "precision: 0.9926, 0.6667\n",
      "recall: 0.7701, 0.0909\n",
      "f score: 0.8673, 0.1600\n",
      "supoort: 174.0000, 44.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9686\n",
      "- Test Score: 0.8687\n",
      "44 of 335 were criminal\n",
      "precision: 1.0000, 0.5000\n",
      "recall: 0.7586, 0.0909\n",
      "f score: 0.8627, 0.1538\n",
      "supoort: 174.0000, 44.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9783\n",
      "- Test Score: 0.8955\n",
      "44 of 335 were criminal\n",
      "precision: 1.0000, 0.8462\n",
      "recall: 0.8333, 0.2500\n",
      "f score: 0.9091, 0.3860\n",
      "supoort: 174.0000, 44.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9731\n",
      "- Test Score: 0.8799\n",
      "43 of 333 were criminal\n",
      "precision: 1.0000, 0.6364\n",
      "recall: 0.7943, 0.1628\n",
      "f score: 0.8854, 0.2593\n",
      "supoort: 175.0000, 43.0000\n",
      "---------------------------\n",
      "- Train Score: 0.9686\n",
      "- Test Score: 0.8649\n",
      "43 of 333 were criminal\n",
      "precision: 0.9854, 0.2500\n",
      "recall: 0.7714, 0.0233\n",
      "f score: 0.8654, 0.0426\n",
      "supoort: 175.0000, 43.0000\n",
      "\n",
      "avg precision: 0.5798\n",
      "avg recall: 0.1236\n",
      "avg f score: 0.2003\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=943)\n",
    "\n",
    "\n",
    "avg_precision = 0.0\n",
    "avg_recall = 0.0\n",
    "avg_fscore = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    prior = y.sum() *1.0 / len(y)\n",
    "    \n",
    "    clf = MultinomialNB(alpha=3.0, class_prior=[1-prior,prior ], fit_prior=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred )) #target_names=target_names\n",
    "    precision_train, recall_train, fscore_train, support_train = precision_recall_fscore_support(y_train,y_pred_train)\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test,y_pred_test)\n",
    "    \n",
    "    print \"---------------------------\"\n",
    "    print \"- Train Score: %0.4f\" % clf.score(X_train, y_train)\n",
    "    print \"- Test Score: %0.4f\" % clf.score(X_test, y_test)\n",
    "    print \"%i of %i were criminal\" % (y_test.sum(), len(y_test))\n",
    "    print \"precision: %0.4f, %0.4f\" % (precision_train[1], precision[1])\n",
    "    print \"recall: %0.4f, %0.4f\" % (recall_train[1], recall[1])\n",
    "    print \"f score: %0.4f, %0.4f\" % (fscore_train[1], fscore[1])\n",
    "    print \"supoort: %0.4f, %0.4f\" % (support_train[1], support[1])\n",
    "    \n",
    "    avg_precision += precision[1]\n",
    "    avg_recall += recall[1]\n",
    "    avg_fscore += fscore[1]\n",
    "    \n",
    "#     break\n",
    "    \n",
    "print \n",
    "print \"avg precision: %0.4f\" %(avg_precision/splits)\n",
    "print \"avg recall: %0.4f\" %(avg_recall/splits)\n",
    "print \"avg f score: %0.4f\" %(avg_fscore/splits)\n",
    "    \n",
    "# clf.fit(X[[0,1,2,3,5,6,7,8,9,10]], y[[0,1,2,3,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO\n",
    "\n",
    "- Add a CV grid search or a Bayes \n",
    "- Think in stacking (one for recall one for precision ;) ) \n",
    "- More data... data exploration...\n",
    "- Try other classifiers...  Logistic, SVC , XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Change of plans\n",
    "\n",
    "Create two classifiers: One optimized for Recall and One optimized for Precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score    : 0.9678, 0.8836\n",
      "avg precision: 1.0000, 1.0000\n",
      "avg recall   : 0.7529, 0.1136\n",
      "avg f score  : 0.8590, 0.2041\n"
     ]
    }
   ],
   "source": [
    "def precision_classifier(df, splits=5):\n",
    "    \n",
    "    vectorizer1 = CountVectorizer(min_df=1, max_df=1, #max_features=700,  \n",
    "                              analyzer='char_wb', ngram_range=(5, 5),\n",
    "                              stop_words=stop_words, binary=True)\n",
    "    \n",
    "    vectorizer1.fit(df[df[\"category\"]==\"Criminal\"].content.values)\n",
    "    \n",
    "    X = vectorizer1.transform(df.content.values)\n",
    "    y = df.category.apply(lambda x:  int(x==\"Criminal\") ).values\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=943)\n",
    "    avg_score = [0.0,0.0]\n",
    "    avg_precision = [0.0,0.0]\n",
    "    avg_recall = [0.0,0.0]\n",
    "    avg_fscore = [0.0,0.0]\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):    \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        prior = y.sum() *1.0 / len(y)\n",
    "\n",
    "        clf = MultinomialNB(alpha=3.0, class_prior=[1-prior,prior ], fit_prior=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "\n",
    "        #train\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_train,y_pred_train)\n",
    "        avg_score[0] += clf.score(X_train, y_train)\n",
    "        avg_precision[0] += prec[1]\n",
    "        avg_recall[0] += rec[1]\n",
    "        avg_fscore[0] += f1[1]\n",
    "        #test\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_test,y_pred_test)\n",
    "        avg_score[1] += clf.score(X_test, y_test)\n",
    "        avg_precision[1] += prec[1]\n",
    "        avg_recall[1] += rec[1]\n",
    "        avg_fscore[1] += f1[1]\n",
    "        \n",
    "        splits =1.0\n",
    "        break\n",
    "\n",
    "    print \"avg score    : %0.4f, %0.4f\" %(avg_score[0]/splits, avg_score[1]/splits )\n",
    "    print \"avg precision: %0.4f, %0.4f\" %(avg_precision[0]/splits, avg_precision[1]/splits  )\n",
    "    print \"avg recall   : %0.4f, %0.4f\" %(avg_recall[0]/splits, avg_recall[1]/splits )\n",
    "    print \"avg f score  : %0.4f, %0.4f\" %(avg_fscore[0]/splits, avg_fscore[1]/splits  )\n",
    "    \n",
    "    return clf, X_test\n",
    "    \n",
    "    \n",
    "clf_prec, X_test_prec = precision_classifier(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score    : 0.9993, 0.1731\n",
      "avg precision: 1.0000, 0.1371\n",
      "avg recall   : 0.9943, 1.0000\n",
      "avg f score  : 0.9971, 0.2411\n"
     ]
    }
   ],
   "source": [
    "def recall_classifier(df, splits=5):\n",
    "    \n",
    "    vectorizer1 = CountVectorizer(min_df=1, max_df=1, #max_features=700,  \n",
    "                              analyzer='char_wb', ngram_range=(5, 5),\n",
    "                              stop_words=stop_words, binary=False)\n",
    "#     vectorizer2 = CountVectorizer(min_df=1, max_df=1,  analyzer='word', stop_words=stop_words, binary=False)\n",
    "    vectorizer2 = TfidfVectorizer(min_df=1,stop_words=stop_words ) \n",
    "    \n",
    "    vectorizer1.fit(df.content.values)\n",
    "    vectorizer2.fit(documents.title.values)\n",
    "    \n",
    "    X1 = vectorizer1.transform(df.content.values)\n",
    "    X2 = vectorizer2.fit_transform(documents.title.values)\n",
    "    X = sp.hstack((X1, X2), format='csr')\n",
    "    y = df.category.apply(lambda x:  int(x==\"Criminal\") ).values\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=943)\n",
    "    avg_score = [0.0,0.0]\n",
    "    avg_precision = [0.0,0.0]\n",
    "    avg_recall = [0.0,0.0]\n",
    "    avg_fscore = [0.0,0.0]\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):    \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        prior = y.sum() *1.0 / len(y)\n",
    "\n",
    "        clf = MultinomialNB(alpha=0.1, class_prior=[1-prior,prior ], fit_prior=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "\n",
    "        #train\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_train,y_pred_train)\n",
    "        avg_score[0] += clf.score(X_train, y_train)\n",
    "        avg_precision[0] += prec[1]\n",
    "        avg_recall[0] += rec[1]\n",
    "        avg_fscore[0] += f1[1]\n",
    "        #test\n",
    "        prec, rec, f1, supp = precision_recall_fscore_support(y_test,y_pred_test)\n",
    "        avg_score[1] += clf.score(X_test, y_test)\n",
    "        avg_precision[1] += prec[1]\n",
    "        avg_recall[1] += rec[1]\n",
    "        avg_fscore[1] += f1[1]\n",
    "        \n",
    "        splits =1.0\n",
    "        break\n",
    "\n",
    "    print \"avg score    : %0.4f, %0.4f\" %(avg_score[0]/splits, avg_score[1]/splits )\n",
    "    print \"avg precision: %0.4f, %0.4f\" %(avg_precision[0]/splits, avg_precision[1]/splits  )\n",
    "    print \"avg recall   : %0.4f, %0.4f\" %(avg_recall[0]/splits, avg_recall[1]/splits )\n",
    "    print \"avg f score  : %0.4f, %0.4f\" %(avg_fscore[0]/splits, avg_fscore[1]/splits  )\n",
    "    \n",
    "    return clf, X_test, y_test\n",
    "    \n",
    "    \n",
    "clf_recall, X_test_recall, y_test = recall_classifier(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.88181818,  1.        ]),\n",
       " array([ 1.        ,  0.11363636]),\n",
       " array([ 0.93719807,  0.20408163]),\n",
       " array([291,  44]))"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = clf_recall.predict(X_test_recall)\n",
    "\n",
    "preds = []\n",
    "for index, val in enumerate(y_pred_test):\n",
    "    if val == 0:\n",
    "        preds.append(val)\n",
    "    else:\n",
    "        z = clf_prec.predict(X_test_prec[index])[0]\n",
    "        preds.append(z)\n",
    "\n",
    "\n",
    "precision_recall_fscore_support(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
